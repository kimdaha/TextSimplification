{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e02c8d1-e653-41a5-a94f-e44c176dbcc5",
   "metadata": {},
   "source": [
    "# 1. 개발 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa242e1-7689-4397-b410-d550e79246c3",
   "metadata": {},
   "source": [
    "### 1.1 필수 라이브러리 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d405d7a-f2c9-4416-bf88-880812a2b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\kim82\\anaconda3\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (6.28.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.19.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.5.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.10.6)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (305.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.10.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: overrides in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.58.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\kim82\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\kim82\\anaconda3\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\kim82\\anaconda3\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kim82\\anaconda3\\lib\\site-packages (0.18.0+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\kim82\\anaconda3\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kim82\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U transformers\n",
    "!pip3 install -q -U datasets\n",
    "!pip3 install -q -U bitsandbytes\n",
    "!pip3 install -q -U peft\n",
    "!pip3 install -q -U trl\n",
    "!pip3 install -q -U accelerate\n",
    "!pip3 install ipywidgets\n",
    "!pip3 install huggingface_hub\n",
    "!pip3 install torch\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa79b6-4720-43d1-baae-41d834011c2c",
   "metadata": {},
   "source": [
    "### 1.2 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7a17e3-b9a1-4a46-8f6e-7710a37a93bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kim82\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f30d7-bfdf-49c5-8c2c-701ad6f15a80",
   "metadata": {},
   "source": [
    "### 1.3 Huggingface 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa22976-7bdf-479d-8c5c-8ab890be537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6be4677559c41b69397162aa9786ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98848a84-680e-4527-bdaf-f5cd7d635348",
   "metadata": {},
   "source": [
    "# 2. Dataset 생성 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa6125-b440-4458-b3dc-142aa7668110",
   "metadata": {},
   "source": [
    "### 2.1 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9031d1af-d554-4852-bae8-006721468543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dahalotto/simman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89cfc2-2123-4e30-8440-c827c9705510",
   "metadata": {},
   "source": [
    "### 2.2 데이터셋 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780a6768-c25e-4816-b944-52e95638ecb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'simplification'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'simplification'],\n",
       "        num_rows: 2486\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'simplification'],\n",
       "        num_rows: 2788\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59da51-bb41-44ea-bd62-9e9bcece871f",
   "metadata": {},
   "source": [
    "### 2.3 데이터셋 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b66ad0-c0ab-4be4-8214-ad02f1b8ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2024-03-27 6:00',\n",
       " 'category': '건강',\n",
       " 'press': '\"조선일보, 어린이조선일보\"',\n",
       " 'title': '속 부글거리고 시도 때도 없이 방귀? 식단 ‘이렇게’ 바꿔야',\n",
       " 'document': '\"사람은 하루 평균 15~20회 방귀를 뀐다. 방귀는 장 속에 있는 공기가 빠져나가는 정상적인 과정이지만, 속이 과도하게 부글거리거나 복부가 부어오르고 방귀 냄새가 심하게 난다면 생활습관을 점검해 볼 필요가 있다. 속 부글거림과 지독한 방귀 냄새의 원인은 장내 미생물 구성 때문인 경우가 많다. 장내 미생물이 섬유질 등 위에서 분해되지 않은 음식물을 분해하는 과정에서 이산화탄소와 수소 및 메탄이 형성되기 때문이다. 장내 미생물 구성에 따라 더 냄새나는 가스가 많이 생성될 수 있으며 일부 사람들은 냄새나는 가스를 생성하는 장내 미생물 유형이 많을 수 있다. 고기를 많이 섭취하면 방귀 냄새가 심해진다. 육류에 많이 함유된 유황이라는 화합물이 장내 미생물에 의해 썩은 달걀 냄새가 나는 황화수소 가스로 분해되기 때문이다. 만약 유제품을 섭취한 뒤 속이 부글거리거나 방귀 횟수가 잦다면 유당불내증 신호일 수 있다. 유당불내증은 체내에 유당을 분해하는 데 필요한 효소인 락타아제가 충분하지 않은 질환으로 소화되지 못한 유당이 대장의 산과 가스에 의해 복부 팽창이나 설사 등을 일으킨다. 유당불내증이 의심된다면 증상이 호전되는지 확인하기 위해 한동안 유제품 섭취를 줄이는 게 도움이 된다. 섭취를 줄인 뒤 장 증상이 나아진다면 유당 함량이 낮거나 없는 제품을 대신 섭취하는 게 좋다. 어떤 종류의 콩이든 섭취량을 늘리면 장기적인 장 건강에 유익하다. 콩은 과일이나 채소보다 더 많은 양의 섬유질이 포함돼 있다. 따라서 콩을 섭취하면 장내 미생물 구성이 다양해지고 복부 팽만을 방지하는 등의 효과가 있다. 단, 콩 섭취량을 늘리면 처음에는 방귀 횟수가 늘어날 수 있다. 따라서 콩 섭취량을 늘릴 때는 식단에 콩 한 스푼을 추가하는 것으로 시작해 몇 주에 걸쳐 반 컵으로 늘리는 것이 좋다. 이후 콩 섭취량을 유지하면 장내 미생물이 섬유질 양에 적응해 가스를 덜 방출하게 된다. 이외에 속 부글거림이나 복부 팽만을 유발하는 생활습관을 고치는 것도 한 가지 방법이다. 식사 속도가 빠르면 음식과 함께 많은 양의 공기가 유입돼 가스가 더 많이 생긴다. 껌을 씹는 습관도 마찬가지로 체내 공기 유입량을 늘린다. 맥주나 탄산음료 섭취도 자제하는 게 좋다. 탄산 속 이산화탄소가 장에 서서히 쌓이면서 가스 생성량이 늘어나기 때문이다.\"',\n",
       " 'link': 'https://health.chosun.com/site/data/html_dir/2024/03/26/2024032601702.html',\n",
       " 'simplification': '\"사람은 하루 평균 15~20번 정도 방귀를 뀝니다. 배출량으로 치면, 최대 1500㎖ 정도의 양이 몸 밖으로 나오는 셈인데요. 소리가 크거나 냄새가 고약해 습관적으로 방귀를 참아 본 적이 있을 거예요. 그런데 방귀를 오래 참으면 배가 아프거나 대변을 잘 보지 못하는 변비에 걸릴 수 있답니다. 평소 음식을 먹고 나면 음식물과 함께 다량의 공기가 몸속으로 들어오는데요. 몸 안에서는 방귀를 통해 체내에 축적된 가스를 내보내게 됩니다. 일부 가스는 혈액에 흡수되고, 숨을 내쉴 때 밖으로 배출되죠. 하지만 제때 방귀를 내보내지 않으면 장내에 가스가 계속 쌓이게 됩니다. 장 속에 가스를 배출시키지 못한채 가스가 계속 쌓이면 복부 팽만을 유발하고요. 복부 팽만은 장에 질소 가스가 쌓이면서, 대장이 부풀어 마치 배에 풍선이 들어있는 것처럼 배가 팽창되는 증상이에요. 심할 경우, 장의 운동 기능이 약해져 불규칙한 배변 습관이 생겨 변비로 이어질 수 있는 거예요. 그런데 유독 방귀를 자주 뀌거나 갑자기 방귀가 많아진 경우, 평소 식습관을 돌이켜보는 게 좋아요. 양배추, 콩, 브로콜리 등 식이섬유가 많은 채소는 장 기능에 좋다고 알려져 있지만 과하게 섭취할 경우 배에 가스가 잘 차기 때문에 평소보다 방귀가 잦아질 수 있거든요. 유제품을 소화시키는 \\'유당분해효소\\'가 적은 사람은 우유·요구르트 같은 유제품을 섭취하면 가스가 잘 찰 수 있고요. 이 외에도 평소 몸을 잘 움직이지 않으면 위장 운동이 떨어져 가스가 잘 차고, 과식 또한 음식물을 소화시키는 데 오랜 시간이 걸리고 위장에도 부담을 줘 방귀가 많아질 수 있답니다.\"'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3036665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GemmaTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 39/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 59/74936:\n",
      "Number of tokens: 1067\n",
      "==================================================\n",
      "Example 64/74936:\n",
      "Number of tokens: 1055\n",
      "==================================================\n",
      "Example 74/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 92/74936:\n",
      "Number of tokens: 1059\n",
      "==================================================\n",
      "Example 94/74936:\n",
      "Number of tokens: 1118\n",
      "==================================================\n",
      "Example 96/74936:\n",
      "Number of tokens: 1060\n",
      "==================================================\n",
      "Example 97/74936:\n",
      "Number of tokens: 1126\n",
      "==================================================\n",
      "Example 109/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 114/74936:\n",
      "Number of tokens: 1091\n",
      "==================================================\n",
      "Example 115/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 132/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 134/74936:\n",
      "Number of tokens: 1052\n",
      "==================================================\n",
      "Example 137/74936:\n",
      "Number of tokens: 1090\n",
      "==================================================\n",
      "Example 144/74936:\n",
      "Number of tokens: 1083\n",
      "==================================================\n",
      "Example 146/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 154/74936:\n",
      "Number of tokens: 1066\n",
      "==================================================\n",
      "Example 182/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 198/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 235/74936:\n",
      "Number of tokens: 1059\n",
      "==================================================\n",
      "Example 236/74936:\n",
      "Number of tokens: 1066\n",
      "==================================================\n",
      "Example 244/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 253/74936:\n",
      "Number of tokens: 1111\n",
      "==================================================\n",
      "Example 254/74936:\n",
      "Number of tokens: 1131\n",
      "==================================================\n",
      "Example 256/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 264/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 267/74936:\n",
      "Number of tokens: 1074\n",
      "==================================================\n",
      "Example 268/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 275/74936:\n",
      "Number of tokens: 1047\n",
      "==================================================\n",
      "Example 287/74936:\n",
      "Number of tokens: 1044\n",
      "==================================================\n",
      "Example 299/74936:\n",
      "Number of tokens: 1218\n",
      "==================================================\n",
      "Example 315/74936:\n",
      "Number of tokens: 1069\n",
      "==================================================\n",
      "Example 320/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 331/74936:\n",
      "Number of tokens: 1050\n",
      "==================================================\n",
      "Example 332/74936:\n",
      "Number of tokens: 1074\n",
      "==================================================\n",
      "Example 334/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 335/74936:\n",
      "Number of tokens: 1083\n",
      "==================================================\n",
      "Example 349/74936:\n",
      "Number of tokens: 1052\n",
      "==================================================\n",
      "Example 377/74936:\n",
      "Number of tokens: 1175\n",
      "==================================================\n",
      "Example 398/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 399/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 455/74936:\n",
      "Number of tokens: 1123\n",
      "==================================================\n",
      "Example 458/74936:\n",
      "Number of tokens: 1117\n",
      "==================================================\n",
      "Example 548/74936:\n",
      "Number of tokens: 1111\n",
      "==================================================\n",
      "Example 558/74936:\n",
      "Number of tokens: 1049\n",
      "==================================================\n",
      "Example 564/74936:\n",
      "Number of tokens: 1098\n",
      "==================================================\n",
      "Example 592/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 603/74936:\n",
      "Number of tokens: 1097\n",
      "==================================================\n",
      "Example 613/74936:\n",
      "Number of tokens: 1081\n",
      "==================================================\n",
      "Example 619/74936:\n",
      "Number of tokens: 1120\n",
      "==================================================\n",
      "Example 630/74936:\n",
      "Number of tokens: 1059\n",
      "==================================================\n",
      "Example 648/74936:\n",
      "Number of tokens: 1065\n",
      "==================================================\n",
      "Example 649/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 661/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 668/74936:\n",
      "Number of tokens: 1052\n",
      "==================================================\n",
      "Example 679/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 688/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 691/74936:\n",
      "Number of tokens: 1057\n",
      "==================================================\n",
      "Example 712/74936:\n",
      "Number of tokens: 1072\n",
      "==================================================\n",
      "Example 722/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 742/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 745/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 762/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 763/74936:\n",
      "Number of tokens: 1098\n",
      "==================================================\n",
      "Example 782/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 785/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 792/74936:\n",
      "Number of tokens: 1055\n",
      "==================================================\n",
      "Example 794/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 802/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 810/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 816/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 836/74936:\n",
      "Number of tokens: 1084\n",
      "==================================================\n",
      "Example 860/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 870/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 880/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 892/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 897/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 899/74936:\n",
      "Number of tokens: 1104\n",
      "==================================================\n",
      "Example 902/74936:\n",
      "Number of tokens: 1091\n",
      "==================================================\n",
      "Example 919/74936:\n",
      "Number of tokens: 1079\n",
      "==================================================\n",
      "Example 920/74936:\n",
      "Number of tokens: 1057\n",
      "==================================================\n",
      "Example 929/74936:\n",
      "Number of tokens: 1070\n",
      "==================================================\n",
      "Example 944/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 947/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 953/74936:\n",
      "Number of tokens: 1053\n",
      "==================================================\n",
      "Example 958/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 960/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 978/74936:\n",
      "Number of tokens: 1058\n",
      "==================================================\n",
      "Example 992/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 994/74936:\n",
      "Number of tokens: 1097\n",
      "==================================================\n",
      "Example 995/74936:\n",
      "Number of tokens: 1053\n",
      "==================================================\n",
      "Example 996/74936:\n",
      "Number of tokens: 1132\n",
      "==================================================\n",
      "Example 998/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 1026/74936:\n",
      "Number of tokens: 1035\n",
      "==================================================\n",
      "Example 1033/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 1052/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 1053/74936:\n",
      "Number of tokens: 1045\n",
      "==================================================\n",
      "Example 1058/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 1059/74936:\n",
      "Number of tokens: 1200\n",
      "==================================================\n",
      "Example 1061/74936:\n",
      "Number of tokens: 1130\n",
      "==================================================\n",
      "Example 1091/74936:\n",
      "Number of tokens: 1656\n",
      "==================================================\n",
      "Example 1123/74936:\n",
      "Number of tokens: 1079\n",
      "==================================================\n",
      "Example 1129/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 1144/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 1149/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 1168/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 1171/74936:\n",
      "Number of tokens: 1065\n",
      "==================================================\n",
      "Example 1184/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 1190/74936:\n",
      "Number of tokens: 1117\n",
      "==================================================\n",
      "Example 1211/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 1220/74936:\n",
      "Number of tokens: 1081\n",
      "==================================================\n",
      "Example 1223/74936:\n",
      "Number of tokens: 1066\n",
      "==================================================\n",
      "Example 1224/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 1227/74936:\n",
      "Number of tokens: 1049\n",
      "==================================================\n",
      "Example 1269/74936:\n",
      "Number of tokens: 1120\n",
      "==================================================\n",
      "Example 1270/74936:\n",
      "Number of tokens: 1066\n",
      "==================================================\n",
      "Example 1276/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 1283/74936:\n",
      "Number of tokens: 1055\n",
      "==================================================\n",
      "Example 1286/74936:\n",
      "Number of tokens: 1078\n",
      "==================================================\n",
      "Example 1296/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 1301/74936:\n",
      "Number of tokens: 1090\n",
      "==================================================\n",
      "Example 1316/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 1337/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 1348/74936:\n",
      "Number of tokens: 1062\n",
      "==================================================\n",
      "Example 1361/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 1378/74936:\n",
      "Number of tokens: 1047\n",
      "==================================================\n",
      "Example 1381/74936:\n",
      "Number of tokens: 1099\n",
      "==================================================\n",
      "Example 1382/74936:\n",
      "Number of tokens: 1065\n",
      "==================================================\n",
      "Example 1450/74936:\n",
      "Number of tokens: 1089\n",
      "==================================================\n",
      "Example 1457/74936:\n",
      "Number of tokens: 1287\n",
      "==================================================\n",
      "Example 1574/74936:\n",
      "Number of tokens: 1144\n",
      "==================================================\n",
      "Example 1665/74936:\n",
      "Number of tokens: 1130\n",
      "==================================================\n",
      "Example 1704/74936:\n",
      "Number of tokens: 1049\n",
      "==================================================\n",
      "Example 1742/74936:\n",
      "Number of tokens: 1142\n",
      "==================================================\n",
      "Example 1773/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 1861/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 1870/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 1871/74936:\n",
      "Number of tokens: 1049\n",
      "==================================================\n",
      "Example 1878/74936:\n",
      "Number of tokens: 1091\n",
      "==================================================\n",
      "Example 1927/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 1938/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 1954/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 1955/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 1970/74936:\n",
      "Number of tokens: 1128\n",
      "==================================================\n",
      "Example 1977/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 2021/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 2052/74936:\n",
      "Number of tokens: 1046\n",
      "==================================================\n",
      "Example 2053/74936:\n",
      "Number of tokens: 1077\n",
      "==================================================\n",
      "Example 2061/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 2083/74936:\n",
      "Number of tokens: 1117\n",
      "==================================================\n",
      "Example 2124/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 2134/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 2230/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 2231/74936:\n",
      "Number of tokens: 1055\n",
      "==================================================\n",
      "Example 2248/74936:\n",
      "Number of tokens: 1072\n",
      "==================================================\n",
      "Example 2249/74936:\n",
      "Number of tokens: 1101\n",
      "==================================================\n",
      "Example 2262/74936:\n",
      "Number of tokens: 1093\n",
      "==================================================\n",
      "Example 2263/74936:\n",
      "Number of tokens: 1047\n",
      "==================================================\n",
      "Example 2270/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 2304/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 2324/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 2364/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 2522/74936:\n",
      "Number of tokens: 1228\n",
      "==================================================\n",
      "Example 2558/74936:\n",
      "Number of tokens: 1051\n",
      "==================================================\n",
      "Example 2575/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 2586/74936:\n",
      "Number of tokens: 1114\n",
      "==================================================\n",
      "Example 2626/74936:\n",
      "Number of tokens: 1175\n",
      "==================================================\n",
      "Example 2823/74936:\n",
      "Number of tokens: 1051\n",
      "==================================================\n",
      "Example 3036/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 3265/74936:\n",
      "Number of tokens: 1257\n",
      "==================================================\n",
      "Example 3386/74936:\n",
      "Number of tokens: 1138\n",
      "==================================================\n",
      "Example 3792/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 4414/74936:\n",
      "Number of tokens: 1035\n",
      "==================================================\n",
      "Example 4434/74936:\n",
      "Number of tokens: 1318\n",
      "==================================================\n",
      "Example 4435/74936:\n",
      "Number of tokens: 1540\n",
      "==================================================\n",
      "Example 4584/74936:\n",
      "Number of tokens: 1212\n",
      "==================================================\n",
      "Example 4646/74936:\n",
      "Number of tokens: 1198\n",
      "==================================================\n",
      "Example 4647/74936:\n",
      "Number of tokens: 1100\n",
      "==================================================\n",
      "Example 4675/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 4704/74936:\n",
      "Number of tokens: 1169\n",
      "==================================================\n",
      "Example 4995/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 4996/74936:\n",
      "Number of tokens: 1212\n",
      "==================================================\n",
      "Example 5013/74936:\n",
      "Number of tokens: 1144\n",
      "==================================================\n",
      "Example 5264/74936:\n",
      "Number of tokens: 1123\n",
      "==================================================\n",
      "Example 5289/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 5421/74936:\n",
      "Number of tokens: 1055\n",
      "==================================================\n",
      "Example 5525/74936:\n",
      "Number of tokens: 1243\n",
      "==================================================\n",
      "Example 5578/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 5857/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 6000/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 6021/74936:\n",
      "Number of tokens: 1140\n",
      "==================================================\n",
      "Example 6093/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 6155/74936:\n",
      "Number of tokens: 1264\n",
      "==================================================\n",
      "Example 6167/74936:\n",
      "Number of tokens: 1299\n",
      "==================================================\n",
      "Example 6190/74936:\n",
      "Number of tokens: 1079\n",
      "==================================================\n",
      "Example 6234/74936:\n",
      "Number of tokens: 1069\n",
      "==================================================\n",
      "Example 6271/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 6365/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 6371/74936:\n",
      "Number of tokens: 1113\n",
      "==================================================\n",
      "Example 6462/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 6466/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 6470/74936:\n",
      "Number of tokens: 1168\n",
      "==================================================\n",
      "Example 6494/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 6542/74936:\n",
      "Number of tokens: 1284\n",
      "==================================================\n",
      "Example 6544/74936:\n",
      "Number of tokens: 1289\n",
      "==================================================\n",
      "Example 6632/74936:\n",
      "Number of tokens: 1397\n",
      "==================================================\n",
      "Example 6665/74936:\n",
      "Number of tokens: 1196\n",
      "==================================================\n",
      "Example 6705/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 6722/74936:\n",
      "Number of tokens: 1233\n",
      "==================================================\n",
      "Example 6746/74936:\n",
      "Number of tokens: 1166\n",
      "==================================================\n",
      "Example 6747/74936:\n",
      "Number of tokens: 1079\n",
      "==================================================\n",
      "Example 6813/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 6842/74936:\n",
      "Number of tokens: 1125\n",
      "==================================================\n",
      "Example 6884/74936:\n",
      "Number of tokens: 1047\n",
      "==================================================\n",
      "Example 7025/74936:\n",
      "Number of tokens: 1369\n",
      "==================================================\n",
      "Example 7050/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 7137/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 7185/74936:\n",
      "Number of tokens: 1267\n",
      "==================================================\n",
      "Example 7406/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 7420/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 7421/74936:\n",
      "Number of tokens: 1180\n",
      "==================================================\n",
      "Example 7426/74936:\n",
      "Number of tokens: 1125\n",
      "==================================================\n",
      "Example 7433/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 7600/74936:\n",
      "Number of tokens: 1238\n",
      "==================================================\n",
      "Example 7670/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 7715/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 7767/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 7951/74936:\n",
      "Number of tokens: 1047\n",
      "==================================================\n",
      "Example 8296/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 8408/74936:\n",
      "Number of tokens: 1097\n",
      "==================================================\n",
      "Example 8507/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 8544/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 8563/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 8879/74936:\n",
      "Number of tokens: 1087\n",
      "==================================================\n",
      "Example 8887/74936:\n",
      "Number of tokens: 1121\n",
      "==================================================\n",
      "Example 8955/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 8990/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 9266/74936:\n",
      "Number of tokens: 1046\n",
      "==================================================\n",
      "Example 9337/74936:\n",
      "Number of tokens: 1051\n",
      "==================================================\n",
      "Example 9397/74936:\n",
      "Number of tokens: 1201\n",
      "==================================================\n",
      "Example 9402/74936:\n",
      "Number of tokens: 1121\n",
      "==================================================\n",
      "Example 9417/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 9448/74936:\n",
      "Number of tokens: 1121\n",
      "==================================================\n",
      "Example 9472/74936:\n",
      "Number of tokens: 1099\n",
      "==================================================\n",
      "Example 9600/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 9812/74936:\n",
      "Number of tokens: 1201\n",
      "==================================================\n",
      "Example 9825/74936:\n",
      "Number of tokens: 1184\n",
      "==================================================\n",
      "Example 9934/74936:\n",
      "Number of tokens: 1139\n",
      "==================================================\n",
      "Example 10038/74936:\n",
      "Number of tokens: 1128\n",
      "==================================================\n",
      "Example 10049/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 10079/74936:\n",
      "Number of tokens: 1045\n",
      "==================================================\n",
      "Example 10087/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 10515/74936:\n",
      "Number of tokens: 1060\n",
      "==================================================\n",
      "Example 10561/74936:\n",
      "Number of tokens: 1035\n",
      "==================================================\n",
      "Example 10636/74936:\n",
      "Number of tokens: 1058\n",
      "==================================================\n",
      "Example 10793/74936:\n",
      "Number of tokens: 1201\n",
      "==================================================\n",
      "Example 11078/74936:\n",
      "Number of tokens: 1060\n",
      "==================================================\n",
      "Example 11264/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 11277/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 11377/74936:\n",
      "Number of tokens: 1071\n",
      "==================================================\n",
      "Example 11381/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 11426/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 11509/74936:\n",
      "Number of tokens: 1318\n",
      "==================================================\n",
      "Example 11540/74936:\n",
      "Number of tokens: 1088\n",
      "==================================================\n",
      "Example 11974/74936:\n",
      "Number of tokens: 1092\n",
      "==================================================\n",
      "Example 12067/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 12105/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 12192/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 12209/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 12300/74936:\n",
      "Number of tokens: 1166\n",
      "==================================================\n",
      "Example 12354/74936:\n",
      "Number of tokens: 1070\n",
      "==================================================\n",
      "Example 12485/74936:\n",
      "Number of tokens: 1193\n",
      "==================================================\n",
      "Example 12530/74936:\n",
      "Number of tokens: 1054\n",
      "==================================================\n",
      "Example 13394/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 13480/74936:\n",
      "Number of tokens: 1104\n",
      "==================================================\n",
      "Example 13551/74936:\n",
      "Number of tokens: 1090\n",
      "==================================================\n",
      "Example 13553/74936:\n",
      "Number of tokens: 1057\n",
      "==================================================\n",
      "Example 13554/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 13791/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 14330/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 14339/74936:\n",
      "Number of tokens: 1074\n",
      "==================================================\n",
      "Example 14381/74936:\n",
      "Number of tokens: 1097\n",
      "==================================================\n",
      "Example 14413/74936:\n",
      "Number of tokens: 1134\n",
      "==================================================\n",
      "Example 14460/74936:\n",
      "Number of tokens: 1101\n",
      "==================================================\n",
      "Example 14479/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 14480/74936:\n",
      "Number of tokens: 1078\n",
      "==================================================\n",
      "Example 14487/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 14505/74936:\n",
      "Number of tokens: 1114\n",
      "==================================================\n",
      "Example 14508/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 14527/74936:\n",
      "Number of tokens: 1098\n",
      "==================================================\n",
      "Example 14531/74936:\n",
      "Number of tokens: 1285\n",
      "==================================================\n",
      "Example 14588/74936:\n",
      "Number of tokens: 1106\n",
      "==================================================\n",
      "Example 14728/74936:\n",
      "Number of tokens: 1368\n",
      "==================================================\n",
      "Example 14756/74936:\n",
      "Number of tokens: 1136\n",
      "==================================================\n",
      "Example 14851/74936:\n",
      "Number of tokens: 1094\n",
      "==================================================\n",
      "Example 14955/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 15115/74936:\n",
      "Number of tokens: 1103\n",
      "==================================================\n",
      "Example 15155/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 15418/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 15422/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 15473/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 15557/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 15579/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 15599/74936:\n",
      "Number of tokens: 1104\n",
      "==================================================\n",
      "Example 15708/74936:\n",
      "Number of tokens: 1103\n",
      "==================================================\n",
      "Example 15753/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 15774/74936:\n",
      "Number of tokens: 1079\n",
      "==================================================\n",
      "Example 15846/74936:\n",
      "Number of tokens: 1051\n",
      "==================================================\n",
      "Example 15850/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 15909/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 15939/74936:\n",
      "Number of tokens: 1240\n",
      "==================================================\n",
      "Example 16011/74936:\n",
      "Number of tokens: 1072\n",
      "==================================================\n",
      "Example 16016/74936:\n",
      "Number of tokens: 1266\n",
      "==================================================\n",
      "Example 16049/74936:\n",
      "Number of tokens: 1152\n",
      "==================================================\n",
      "Example 16085/74936:\n",
      "Number of tokens: 1092\n",
      "==================================================\n",
      "Example 16119/74936:\n",
      "Number of tokens: 1233\n",
      "==================================================\n",
      "Example 16135/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 16137/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 16204/74936:\n",
      "Number of tokens: 1073\n",
      "==================================================\n",
      "Example 16238/74936:\n",
      "Number of tokens: 1087\n",
      "==================================================\n",
      "Example 16482/74936:\n",
      "Number of tokens: 1140\n",
      "==================================================\n",
      "Example 16484/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 16489/74936:\n",
      "Number of tokens: 1166\n",
      "==================================================\n",
      "Example 16490/74936:\n",
      "Number of tokens: 1082\n",
      "==================================================\n",
      "Example 16492/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 16497/74936:\n",
      "Number of tokens: 1120\n",
      "==================================================\n",
      "Example 16501/74936:\n",
      "Number of tokens: 1045\n",
      "==================================================\n",
      "Example 16506/74936:\n",
      "Number of tokens: 1142\n",
      "==================================================\n",
      "Example 16507/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 16535/74936:\n",
      "Number of tokens: 1091\n",
      "==================================================\n",
      "Example 16661/74936:\n",
      "Number of tokens: 1152\n",
      "==================================================\n",
      "Example 16694/74936:\n",
      "Number of tokens: 1093\n",
      "==================================================\n",
      "Example 16747/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 16819/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 16821/74936:\n",
      "Number of tokens: 1245\n",
      "==================================================\n",
      "Example 16823/74936:\n",
      "Number of tokens: 1045\n",
      "==================================================\n",
      "Example 16841/74936:\n",
      "Number of tokens: 1066\n",
      "==================================================\n",
      "Example 16876/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 16878/74936:\n",
      "Number of tokens: 1073\n",
      "==================================================\n",
      "Example 16890/74936:\n",
      "Number of tokens: 1084\n",
      "==================================================\n",
      "Example 16960/74936:\n",
      "Number of tokens: 1072\n",
      "==================================================\n",
      "Example 17397/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 17445/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 17611/74936:\n",
      "Number of tokens: 1072\n",
      "==================================================\n",
      "Example 17665/74936:\n",
      "Number of tokens: 1218\n",
      "==================================================\n",
      "Example 17806/74936:\n",
      "Number of tokens: 1142\n",
      "==================================================\n",
      "Example 17898/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 18064/74936:\n",
      "Number of tokens: 1053\n",
      "==================================================\n",
      "Example 18198/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 18205/74936:\n",
      "Number of tokens: 1066\n",
      "==================================================\n",
      "Example 18207/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 18291/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 18317/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 18385/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 18388/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 18414/74936:\n",
      "Number of tokens: 1127\n",
      "==================================================\n",
      "Example 18423/74936:\n",
      "Number of tokens: 1125\n",
      "==================================================\n",
      "Example 18751/74936:\n",
      "Number of tokens: 1261\n",
      "==================================================\n",
      "Example 18755/74936:\n",
      "Number of tokens: 1334\n",
      "==================================================\n",
      "Example 18787/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 18852/74936:\n",
      "Number of tokens: 1232\n",
      "==================================================\n",
      "Example 18856/74936:\n",
      "Number of tokens: 1139\n",
      "==================================================\n",
      "Example 18866/74936:\n",
      "Number of tokens: 1084\n",
      "==================================================\n",
      "Example 18958/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 19127/74936:\n",
      "Number of tokens: 1123\n",
      "==================================================\n",
      "Example 19147/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 19207/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 19285/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 19288/74936:\n",
      "Number of tokens: 1242\n",
      "==================================================\n",
      "Example 19292/74936:\n",
      "Number of tokens: 1082\n",
      "==================================================\n",
      "Example 19298/74936:\n",
      "Number of tokens: 1414\n",
      "==================================================\n",
      "Example 19357/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 19448/74936:\n",
      "Number of tokens: 1156\n",
      "==================================================\n",
      "Example 19522/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 19525/74936:\n",
      "Number of tokens: 1109\n",
      "==================================================\n",
      "Example 19526/74936:\n",
      "Number of tokens: 1114\n",
      "==================================================\n",
      "Example 19528/74936:\n",
      "Number of tokens: 1103\n",
      "==================================================\n",
      "Example 19547/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 19732/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 19767/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 19834/74936:\n",
      "Number of tokens: 1028\n",
      "==================================================\n",
      "Example 19888/74936:\n",
      "Number of tokens: 1069\n",
      "==================================================\n",
      "Example 19937/74936:\n",
      "Number of tokens: 1045\n",
      "==================================================\n",
      "Example 20010/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 20138/74936:\n",
      "Number of tokens: 1305\n",
      "==================================================\n",
      "Example 20196/74936:\n",
      "Number of tokens: 1183\n",
      "==================================================\n",
      "Example 20273/74936:\n",
      "Number of tokens: 1054\n",
      "==================================================\n",
      "Example 20285/74936:\n",
      "Number of tokens: 1077\n",
      "==================================================\n",
      "Example 20287/74936:\n",
      "Number of tokens: 1057\n",
      "==================================================\n",
      "Example 20298/74936:\n",
      "Number of tokens: 1156\n",
      "==================================================\n",
      "Example 20492/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 20701/74936:\n",
      "Number of tokens: 1052\n",
      "==================================================\n",
      "Example 20778/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 20868/74936:\n",
      "Number of tokens: 1220\n",
      "==================================================\n",
      "Example 20918/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 21628/74936:\n",
      "Number of tokens: 1231\n",
      "==================================================\n",
      "Example 21629/74936:\n",
      "Number of tokens: 1144\n",
      "==================================================\n",
      "Example 21908/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 21918/74936:\n",
      "Number of tokens: 1080\n",
      "==================================================\n",
      "Example 21959/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 22283/74936:\n",
      "Number of tokens: 1039\n",
      "==================================================\n",
      "Example 22284/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 22754/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 22755/74936:\n",
      "Number of tokens: 1161\n",
      "==================================================\n",
      "Example 22885/74936:\n",
      "Number of tokens: 1157\n",
      "==================================================\n",
      "Example 22894/74936:\n",
      "Number of tokens: 1127\n",
      "==================================================\n",
      "Example 22982/74936:\n",
      "Number of tokens: 1081\n",
      "==================================================\n",
      "Example 23129/74936:\n",
      "Number of tokens: 1186\n",
      "==================================================\n",
      "Example 23435/74936:\n",
      "Number of tokens: 1072\n",
      "==================================================\n",
      "Example 23535/74936:\n",
      "Number of tokens: 1080\n",
      "==================================================\n",
      "Example 23539/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 23542/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 23551/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 23566/74936:\n",
      "Number of tokens: 1094\n",
      "==================================================\n",
      "Example 23639/74936:\n",
      "Number of tokens: 1254\n",
      "==================================================\n",
      "Example 23663/74936:\n",
      "Number of tokens: 1074\n",
      "==================================================\n",
      "Example 23675/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 23688/74936:\n",
      "Number of tokens: 1077\n",
      "==================================================\n",
      "Example 23890/74936:\n",
      "Number of tokens: 1053\n",
      "==================================================\n",
      "Example 23968/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 23997/74936:\n",
      "Number of tokens: 1096\n",
      "==================================================\n",
      "Example 24011/74936:\n",
      "Number of tokens: 1058\n",
      "==================================================\n",
      "Example 24338/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 24343/74936:\n",
      "Number of tokens: 1067\n",
      "==================================================\n",
      "Example 24345/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 24526/74936:\n",
      "Number of tokens: 1084\n",
      "==================================================\n",
      "Example 24722/74936:\n",
      "Number of tokens: 1065\n",
      "==================================================\n",
      "Example 24730/74936:\n",
      "Number of tokens: 1160\n",
      "==================================================\n",
      "Example 25137/74936:\n",
      "Number of tokens: 1153\n",
      "==================================================\n",
      "Example 25237/74936:\n",
      "Number of tokens: 1269\n",
      "==================================================\n",
      "Example 25474/74936:\n",
      "Number of tokens: 1047\n",
      "==================================================\n",
      "Example 25722/74936:\n",
      "Number of tokens: 1152\n",
      "==================================================\n",
      "Example 25724/74936:\n",
      "Number of tokens: 1080\n",
      "==================================================\n",
      "Example 25732/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 25769/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 25948/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 26015/74936:\n",
      "Number of tokens: 1385\n",
      "==================================================\n",
      "Example 26416/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 26442/74936:\n",
      "Number of tokens: 1132\n",
      "==================================================\n",
      "Example 26561/74936:\n",
      "Number of tokens: 1077\n",
      "==================================================\n",
      "Example 26641/74936:\n",
      "Number of tokens: 1385\n",
      "==================================================\n",
      "Example 26873/74936:\n",
      "Number of tokens: 1086\n",
      "==================================================\n",
      "Example 27181/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 27193/74936:\n",
      "Number of tokens: 1189\n",
      "==================================================\n",
      "Example 27222/74936:\n",
      "Number of tokens: 1462\n",
      "==================================================\n",
      "Example 27244/74936:\n",
      "Number of tokens: 1060\n",
      "==================================================\n",
      "Example 27253/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 27325/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 27418/74936:\n",
      "Number of tokens: 1064\n",
      "==================================================\n",
      "Example 27512/74936:\n",
      "Number of tokens: 1070\n",
      "==================================================\n",
      "Example 27575/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 27599/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 27600/74936:\n",
      "Number of tokens: 1090\n",
      "==================================================\n",
      "Example 27970/74936:\n",
      "Number of tokens: 1082\n",
      "==================================================\n",
      "Example 28108/74936:\n",
      "Number of tokens: 1035\n",
      "==================================================\n",
      "Example 28244/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 28257/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 28278/74936:\n",
      "Number of tokens: 1055\n",
      "==================================================\n",
      "Example 28284/74936:\n",
      "Number of tokens: 1043\n",
      "==================================================\n",
      "Example 28294/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 28298/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 28525/74936:\n",
      "Number of tokens: 1052\n",
      "==================================================\n",
      "Example 28635/74936:\n",
      "Number of tokens: 1040\n",
      "==================================================\n",
      "Example 28644/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 28646/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 28796/74936:\n",
      "Number of tokens: 1057\n",
      "==================================================\n",
      "Example 28873/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 28949/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 29438/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 29570/74936:\n",
      "Number of tokens: 1048\n",
      "==================================================\n",
      "Example 29627/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 29629/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 29631/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 29723/74936:\n",
      "Number of tokens: 1191\n",
      "==================================================\n",
      "Example 29788/74936:\n",
      "Number of tokens: 1031\n",
      "==================================================\n",
      "Example 29792/74936:\n",
      "Number of tokens: 1641\n",
      "==================================================\n",
      "Example 29871/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 29884/74936:\n",
      "Number of tokens: 1078\n",
      "==================================================\n",
      "Example 30087/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 30091/74936:\n",
      "Number of tokens: 1051\n",
      "==================================================\n",
      "Example 30097/74936:\n",
      "Number of tokens: 1069\n",
      "==================================================\n",
      "Example 30222/74936:\n",
      "Number of tokens: 1088\n",
      "==================================================\n",
      "Example 30496/74936:\n",
      "Number of tokens: 1125\n",
      "==================================================\n",
      "Example 30564/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 30630/74936:\n",
      "Number of tokens: 1435\n",
      "==================================================\n",
      "Example 30670/74936:\n",
      "Number of tokens: 1045\n",
      "==================================================\n",
      "Example 30780/74936:\n",
      "Number of tokens: 1054\n",
      "==================================================\n",
      "Example 30895/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 30917/74936:\n",
      "Number of tokens: 1247\n",
      "==================================================\n",
      "Example 31331/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 31357/74936:\n",
      "Number of tokens: 1389\n",
      "==================================================\n",
      "Example 31468/74936:\n",
      "Number of tokens: 1062\n",
      "==================================================\n",
      "Example 31533/74936:\n",
      "Number of tokens: 1117\n",
      "==================================================\n",
      "Example 31655/74936:\n",
      "Number of tokens: 1258\n",
      "==================================================\n",
      "Example 31881/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 31932/74936:\n",
      "Number of tokens: 1228\n",
      "==================================================\n",
      "Example 31969/74936:\n",
      "Number of tokens: 1035\n",
      "==================================================\n",
      "Example 32000/74936:\n",
      "Number of tokens: 1117\n",
      "==================================================\n",
      "Example 32121/74936:\n",
      "Number of tokens: 1049\n",
      "==================================================\n",
      "Example 32148/74936:\n",
      "Number of tokens: 1122\n",
      "==================================================\n",
      "Example 32258/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 32268/74936:\n",
      "Number of tokens: 1071\n",
      "==================================================\n",
      "Example 32814/74936:\n",
      "Number of tokens: 1075\n",
      "==================================================\n",
      "Example 32816/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 32845/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 32891/74936:\n",
      "Number of tokens: 1116\n",
      "==================================================\n",
      "Example 32896/74936:\n",
      "Number of tokens: 1125\n",
      "==================================================\n",
      "Example 32956/74936:\n",
      "Number of tokens: 1088\n",
      "==================================================\n",
      "Example 32957/74936:\n",
      "Number of tokens: 1063\n",
      "==================================================\n",
      "Example 32959/74936:\n",
      "Number of tokens: 1109\n",
      "==================================================\n",
      "Example 33002/74936:\n",
      "Number of tokens: 1145\n",
      "==================================================\n",
      "Example 33064/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 33196/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 33267/74936:\n",
      "Number of tokens: 1112\n",
      "==================================================\n",
      "Example 33457/74936:\n",
      "Number of tokens: 1025\n",
      "==================================================\n",
      "Example 33486/74936:\n",
      "Number of tokens: 1033\n",
      "==================================================\n",
      "Example 33490/74936:\n",
      "Number of tokens: 1095\n",
      "==================================================\n",
      "Example 33611/74936:\n",
      "Number of tokens: 1036\n",
      "==================================================\n",
      "Example 33672/74936:\n",
      "Number of tokens: 1360\n",
      "==================================================\n",
      "Example 34014/74936:\n",
      "Number of tokens: 1100\n",
      "==================================================\n",
      "Example 34215/74936:\n",
      "Number of tokens: 1093\n",
      "==================================================\n",
      "Example 34349/74936:\n",
      "Number of tokens: 1118\n",
      "==================================================\n",
      "Example 34435/74936:\n",
      "Number of tokens: 1135\n",
      "==================================================\n",
      "Example 34635/74936:\n",
      "Number of tokens: 1032\n",
      "==================================================\n",
      "Example 34795/74936:\n",
      "Number of tokens: 1136\n",
      "==================================================\n",
      "Example 35084/74936:\n",
      "Number of tokens: 1272\n",
      "==================================================\n",
      "Example 35575/74936:\n",
      "Number of tokens: 1089\n",
      "==================================================\n",
      "Example 35576/74936:\n",
      "Number of tokens: 1107\n",
      "==================================================\n",
      "Example 35578/74936:\n",
      "Number of tokens: 1069\n",
      "==================================================\n",
      "Example 35580/74936:\n",
      "Number of tokens: 1145\n",
      "==================================================\n",
      "Example 35607/74936:\n",
      "Number of tokens: 1099\n",
      "==================================================\n",
      "Example 35685/74936:\n",
      "Number of tokens: 1159\n",
      "==================================================\n",
      "Example 35740/74936:\n",
      "Number of tokens: 1078\n",
      "==================================================\n",
      "Example 35827/74936:\n",
      "Number of tokens: 1116\n",
      "==================================================\n",
      "Example 35896/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 35937/74936:\n",
      "Number of tokens: 1122\n",
      "==================================================\n",
      "Example 35973/74936:\n",
      "Number of tokens: 1030\n",
      "==================================================\n",
      "Example 35982/74936:\n",
      "Number of tokens: 1111\n",
      "==================================================\n",
      "Example 36007/74936:\n",
      "Number of tokens: 1115\n",
      "==================================================\n",
      "Example 36011/74936:\n",
      "Number of tokens: 1056\n",
      "==================================================\n",
      "Example 36013/74936:\n",
      "Number of tokens: 1172\n",
      "==================================================\n",
      "Example 36027/74936:\n",
      "Number of tokens: 1116\n",
      "==================================================\n",
      "Example 36028/74936:\n",
      "Number of tokens: 1093\n",
      "==================================================\n",
      "Example 36034/74936:\n",
      "Number of tokens: 1042\n",
      "==================================================\n",
      "Example 36122/74936:\n",
      "Number of tokens: 1093\n",
      "==================================================\n",
      "Example 36462/74936:\n",
      "Number of tokens: 1186\n",
      "==================================================\n",
      "Example 36463/74936:\n",
      "Number of tokens: 1224\n",
      "==================================================\n",
      "Example 36485/74936:\n",
      "Number of tokens: 1071\n",
      "==================================================\n",
      "Example 36491/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 36503/74936:\n",
      "Number of tokens: 1038\n",
      "==================================================\n",
      "Example 36512/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 36538/74936:\n",
      "Number of tokens: 1085\n",
      "==================================================\n",
      "Example 36571/74936:\n",
      "Number of tokens: 1052\n",
      "==================================================\n",
      "Example 36578/74936:\n",
      "Number of tokens: 1029\n",
      "==================================================\n",
      "Example 37028/74936:\n",
      "Number of tokens: 1065\n",
      "==================================================\n",
      "Example 37076/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 37196/74936:\n",
      "Number of tokens: 1076\n",
      "==================================================\n",
      "Example 37385/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 37529/74936:\n",
      "Number of tokens: 1093\n",
      "==================================================\n",
      "Example 37599/74936:\n",
      "Number of tokens: 1065\n",
      "==================================================\n",
      "Example 37612/74936:\n",
      "Number of tokens: 1046\n",
      "==================================================\n",
      "Example 37636/74936:\n",
      "Number of tokens: 1037\n",
      "==================================================\n",
      "Example 37677/74936:\n",
      "Number of tokens: 1221\n",
      "==================================================\n",
      "Example 37682/74936:\n",
      "Number of tokens: 1335\n",
      "==================================================\n",
      "Example 37726/74936:\n",
      "Number of tokens: 1380\n",
      "==================================================\n",
      "Example 37728/74936:\n",
      "Number of tokens: 1401\n",
      "==================================================\n",
      "Example 37729/74936:\n",
      "Number of tokens: 1077\n",
      "==================================================\n",
      "Example 37734/74936:\n",
      "Number of tokens: 1183\n",
      "==================================================\n",
      "Example 37739/74936:\n",
      "Number of tokens: 1068\n",
      "==================================================\n",
      "Example 37741/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 37882/74936:\n",
      "Number of tokens: 1095\n",
      "==================================================\n",
      "Example 37917/74936:\n",
      "Number of tokens: 1051\n",
      "==================================================\n",
      "Example 38090/74936:\n",
      "Number of tokens: 1475\n",
      "==================================================\n",
      "Example 38113/74936:\n",
      "Number of tokens: 1537\n",
      "==================================================\n",
      "Example 38237/74936:\n",
      "Number of tokens: 1087\n",
      "==================================================\n",
      "Example 38313/74936:\n",
      "Number of tokens: 1123\n",
      "==================================================\n",
      "Example 38506/74936:\n",
      "Number of tokens: 1203\n",
      "==================================================\n",
      "Example 38529/74936:\n",
      "Number of tokens: 1249\n",
      "==================================================\n",
      "Example 38530/74936:\n",
      "Number of tokens: 1092\n",
      "==================================================\n",
      "Example 38756/74936:\n",
      "Number of tokens: 1294\n",
      "==================================================\n",
      "Example 38842/74936:\n",
      "Number of tokens: 1137\n",
      "==================================================\n",
      "Example 38866/74936:\n",
      "Number of tokens: 1026\n",
      "==================================================\n",
      "Example 38898/74936:\n",
      "Number of tokens: 1820\n",
      "==================================================\n",
      "Example 38939/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 38976/74936:\n",
      "Number of tokens: 1353\n",
      "==================================================\n",
      "Example 39001/74936:\n",
      "Number of tokens: 1153\n",
      "==================================================\n",
      "Example 39028/74936:\n",
      "Number of tokens: 1069\n",
      "==================================================\n",
      "Example 39030/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n",
      "Example 39060/74936:\n",
      "Number of tokens: 1560\n",
      "==================================================\n",
      "Example 39095/74936:\n",
      "Number of tokens: 1046\n",
      "==================================================\n",
      "Example 39112/74936:\n",
      "Number of tokens: 1041\n",
      "==================================================\n",
      "Example 39120/74936:\n",
      "Number of tokens: 1034\n",
      "==================================================\n",
      "Example 39131/74936:\n",
      "Number of tokens: 1191\n",
      "==================================================\n",
      "Example 39258/74936:\n",
      "Number of tokens: 1094\n",
      "==================================================\n",
      "Example 39261/74936:\n",
      "Number of tokens: 1027\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 1초 쉬기\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#토큰 측정\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import time\n",
    "# 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"google/gemma-1.1-2b-it\")\n",
    "\n",
    "# 데이터셋의 첫 번째 훈련 예시의 텍스트 가져오기\n",
    "num_examples = len(dataset['train'])\n",
    "\n",
    "# 1초마다 데이터셋의 예시를 출력하는 반복문\n",
    "for i in range(num_examples):\n",
    "    # 현재 예시의 텍스트 가져오기\n",
    "    text = dataset['train'][i]['text']\n",
    "    \n",
    "    # 토큰화\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # 토큰의 개수가 1000개를 넘는 경우에만 출력\n",
    "    if len(tokens) > 1024:\n",
    "        # 결과 출력\n",
    "        print(f\"Example {i + 1}/{num_examples}:\")\n",
    "        print(f\"Number of tokens: {len(tokens)}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 1초 쉬기\n",
    "        time.sleep(0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GemmaTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \"경기 이천시에 있는 정수장에서 수중생물의 유충이 발견돼 주민 불안이 커지고 있다. 애벌레가 깔따구 유충으로 드러나면서 깔따구의 유해성에 대한 관심도 덩달아 커지고 있다. 지난 21일, 환경부에 따르면 이천정수장 내 11곳에 대한 모니터링 과정에서 깔따구 유충 5개체가 발견됐다. 이후 이천시 상하수도사업소는 한강유역환경청, 한국수자원공사와 함께 해당 정수장의 취수정, 침전지, 정수지, 배수지 등 상수도 시설을 긴급 점검하고 있다고 22일 밝혔다. 아울러 정수장 모래 여과지의 역세척 주기를 종전 60시간에서 36시간으로 단축하고, 수중생물 유충 성장을 저해하는 염소 성분의 주입을 정수 전 처리 공정에서 강화해 수돗물의 잔류염소 수치를 종전 0.5~0.8 ppm에서 1~1.2 ppm으로 높여 관리하기로 했다. 또 공정별 방충 시설을 보완하고, 내외부 청소 등의 조치도 강화해 더욱 안전한 수돗물을 공급할 방침이다. 현재 이천정수장을 거쳐 정수된 수돗물은 단수 없이 급수지역인 부발읍, 신둔면, 백사면, 마장면, 창전동, 관고동 등에 공급되고 있다. 시는 불안해하는 주민들을 위해 수자원공사와 도내 지자체로부터 병입수(병에 든 수돗물)를 지원받아 공급하기로 했다. 이천시 상하수도는 환경부와 수자원공사, 관련 전문가들이 유충 유입 원인은 역학조사하고 있다고 밝히며 당분간 마시는 물로 사용은 자제하고 식수로 사용할 경우 끓여서 먹도록 해달라고 당부했다. 한편, 깔따구는 모기와 비슷하게 생긴 곤충의 일종이다. 성충은 입이 없어 사람을 물지 않고 감염병도 옮기지 않는다. 다만 불쾌감과 혐오감을 일으키기 때문에 학계에서는 ‘불쾌해충’으로 분류한다. 단, 깔따구의 유충은 오염된 물에 있는 유기물을 먹고 자라기 때문에 유충의 서식 여부가 수질을 판단하는 기준이 되기도 한다. 통상 깔따구 유충은 2~4급수에서 자란다. 우리나라에는 약 200여종의 깔따구가 서식하는데 1급수에 사는 종도 있다. 수돗물에서 나온 깔따구 유충을 먹었더라도 크게 걱정할 필요는 없다. 직접적으로 인체에 피해를 끼치진 않기 때문이다. 기생충이 아니기 때문에 섭취했더라도 위에서 다 소화되므로 따로 구충제를 복용할 필요는 없다. 다만 곤충 알레르기가 있는 사람은 증상을 겪을 수도 있다. 또 피부가 예민한 사람이 깔따구 유충과 접촉했을 때 접촉성 피부염에 걸릴 수 있다는 해외 연구결과도 있다.\"\n",
      "Tokens: ['\"', '경', '기', '▁이', '천', '시', '에', '▁있는', '▁정', '수', '장', '에서', '▁수', '중', '생', '물', '의', '▁유', '충', '이', '▁발', '견', '돼', '▁주', '민', '▁불', '안', '이', '▁커', '지', '고', '▁있다', '.', '▁애', '벌', '레', '가', '▁', '깔', '따', '구', '▁유', '충', '으로', '▁드', '러나', '면', '서', '▁', '깔', '따', '구', '의', '▁유', '해', '성', '에', '▁대한', '▁관', '심', '도', '▁', '덩', '달', '아', '▁커', '지', '고', '▁있다', '.', '▁지', '난', '▁', '2', '1', '일', ',', '▁환', '경', '부', '에', '▁따', '르', '면', '▁이', '천', '정', '수', '장', '▁내', '▁', '1', '1', '곳', '에', '▁대한', '▁모', '니', '터', '링', '▁과', '정', '에서', '▁', '깔', '따', '구', '▁유', '충', '▁', '5', '개', '체', '가', '▁발', '견', '됐', '다', '.', '▁이', '후', '▁이', '천', '시', '▁상', '하', '수', '도', '사', '업', '소', '는', '▁한', '강', '유', '역', '환', '경', '청', ',', '▁한국', '수', '자', '원', '공', '사', '와', '▁함께', '▁해', '당', '▁정', '수', '장', '의', '▁취', '수', '정', ',', '▁', '침', '전', '지', ',', '▁정', '수', '지', ',', '▁배', '수', '지', '▁등', '▁상', '수', '도', '▁시', '설', '을', '▁', '긴', '급', '▁점', '검', '하고', '▁있다', '고', '▁', '2', '2', '일', '▁', '밝', '혔', '다', '.', '▁아', '울', '러', '▁정', '수', '장', '▁모', '래', '▁여', '과', '지', '의', '▁역', '세', '척', '▁주', '기를', '▁종', '전', '▁', '6', '0', '시간', '에서', '▁', '3', '6', '시간', '으로', '▁단', '축', '하고', ',', '▁수', '중', '생', '물', '▁유', '충', '▁성', '장', '을', '▁저', '해', '하는', '▁', '염', '소', '▁성', '분', '의', '▁주', '입', '을', '▁정', '수', '▁전', '▁처리', '▁공', '정', '에서', '▁강', '화', '해', '▁수', '돗', '물', '의', '▁', '잔', '류', '염', '소', '▁수', '치', '를', '▁종', '전', '▁', '0', '.', '5', '~', '0', '.', '8', '▁ppm', '에서', '▁', '1', '~', '1', '.', '2', '▁ppm', '으로', '▁높', '여', '▁관리', '하기', '로', '▁', '했다', '.', '▁또', '▁공', '정', '별', '▁방', '충', '▁시', '설', '을', '▁보', '완', '하고', ',', '▁내', '외부', '▁청', '소', '▁등', '의', '▁조', '치', '도', '▁강', '화', '해', '▁더', '욱', '▁안', '전', '한', '▁수', '돗', '물', '을', '▁공', '급', '할', '▁방', '침', '이다', '.', '▁현재', '▁이', '천', '정', '수', '장', '을', '▁거', '쳐', '▁정', '수', '된', '▁수', '돗', '물', '은', '▁단', '수', '▁없', '이', '▁', '급', '수', '지', '역', '인', '▁부', '발', '읍', ',', '▁신', '둔', '면', ',', '▁백', '사', '면', ',', '▁마', '장', '면', ',', '▁창', '전', '동', ',', '▁관', '고', '동', '▁등', '에', '▁공', '급', '되', '고', '▁있다', '.', '▁시', '는', '▁불', '안', '해', '하는', '▁주', '민', '들을', '▁위해', '▁수', '자', '원', '공', '사', '와', '▁도', '내', '▁지', '자', '체', '로', '부터', '▁병', '입', '수', '(', '병', '에', '▁', '든', '▁수', '돗', '물', ')', '를', '▁지원', '받', '아', '▁공', '급', '하기', '로', '▁', '했다', '.', '▁이', '천', '시', '▁상', '하', '수', '도', '는', '▁환', '경', '부', '와', '▁수', '자', '원', '공', '사', ',', '▁관련', '▁전', '문', '가', '들이', '▁유', '충', '▁유', '입', '▁원', '인', '은', '▁역', '학', '조', '사', '하고', '▁있다', '고', '▁', '밝', '히', '며', '▁당', '분', '간', '▁마', '시', '는', '▁물', '로', '▁사용', '은', '▁자', '제', '하고', '▁식', '수', '로', '▁사용', '할', '▁경우', '▁', '끓', '여', '서', '▁먹', '도록', '▁해', '달', '라고', '▁당', '부', '했다', '.', '▁한', '편', ',', '▁', '깔', '따', '구', '는', '▁모', '기', '와', '▁비', '슷', '하게', '▁생', '긴', '▁', '곤', '충', '의', '▁일', '종', '이다', '.', '▁성', '충', '은', '▁입', '이', '▁없', '어', '▁사람', '을', '▁물', '지', '▁않', '고', '▁감', '염', '병', '도', '▁', '옮', '기', '지', '▁않는', '다', '.', '▁다', '만', '▁불', '쾌', '감', '과', '▁', '혐', '오', '감', '을', '▁일', '으', '키', '기', '▁때문에', '▁학', '계', '에서는', '▁‘', '불', '쾌', '해', '충', '’', '으로', '▁분', '류', '한다', '.', '▁단', ',', '▁', '깔', '따', '구', '의', '▁유', '충', '은', '▁오', '염', '된', '▁물', '에', '▁있는', '▁유', '기', '물', '을', '▁먹', '고', '▁자', '라', '기', '▁때문에', '▁유', '충', '의', '▁서', '식', '▁여', '부', '가', '▁수', '질', '을', '▁판', '단', '하는', '▁기', '준', '이', '▁되', '기도', '▁한다', '.', '▁통', '상', '▁', '깔', '따', '구', '▁유', '충', '은', '▁', '2', '~', '4', '급', '수', '에서', '▁자', '란', '다', '.', '▁우리', '나', '라', '에는', '▁약', '▁', '2', '0', '0', '여', '종', '의', '▁', '깔', '따', '구', '가', '▁서', '식', '하는', '데', '▁', '1', '급', '수', '에', '▁사', '는', '▁종', '도', '▁있다', '.', '▁수', '돗', '물', '에서', '▁나', '온', '▁', '깔', '따', '구', '▁유', '충', '을', '▁먹', '었', '더', '라', '도', '▁크', '게', '▁', '걱', '정', '할', '▁필요', '는', '▁없', '다', '.', '▁직', '접', '적으로', '▁인', '체', '에', '▁피', '해', '를', '▁', '끼', '치', '진', '▁않', '기', '▁때문', '이다', '.', '▁기', '생', '충', '이', '▁아니', '기', '▁때문에', '▁', '섭', '취', '했', '더', '라', '도', '▁위', '에서', '▁다', '▁소', '화', '되', '므로', '▁따', '로', '▁구', '충', '제', '를', '▁복', '용', '할', '▁필요', '는', '▁없', '다', '.', '▁다', '만', '▁', '곤', '충', '▁알', '레', '르', '기', '가', '▁있는', '▁사람', '은', '▁증', '상', '을', '▁', '겪', '을', '▁수', '도', '▁있다', '.', '▁또', '▁피', '부', '가', '▁예', '민', '한', '▁사람', '이', '▁', '깔', '따', '구', '▁유', '충', '과', '▁접', '촉', '했', '을', '▁때', '▁접', '촉', '성', '▁피', '부', '염', '에', '▁걸', '릴', '▁수', '▁있다', '는', '▁해', '외', '▁연구', '결', '과', '도', '▁있다', '.\"']\n",
      "Token IDs: [235281, 237392, 236386, 11464, 239250, 236569, 236179, 72941, 35467, 236669, 237199, 22803, 22618, 237935, 237889, 238256, 236137, 46355, 240722, 235832, 66144, 241253, 243960, 40712, 238754, 83133, 238179, 235832, 134512, 236183, 236464, 69581, 235265, 122096, 241588, 237990, 236361, 235248, 245083, 240109, 237302, 46355, 240722, 26291, 99028, 122865, 237722, 236554, 235248, 245083, 240109, 237302, 236137, 46355, 237138, 237154, 236179, 71100, 55526, 239308, 236840, 235248, 245112, 239522, 236655, 134512, 236183, 236464, 69581, 235265, 34805, 240198, 235248, 235284, 235274, 236666, 235269, 161409, 237392, 237092, 236179, 103293, 238500, 237722, 11464, 239250, 236864, 236669, 237199, 58272, 235248, 235274, 235274, 241732, 236179, 71100, 34459, 236405, 237524, 239074, 65084, 236864, 22803, 235248, 245083, 240109, 237302, 46355, 240722, 235248, 235308, 237936, 238308, 236361, 66144, 241253, 244908, 236039, 235265, 11464, 238612, 11464, 239250, 236569, 36203, 236345, 236669, 236840, 236417, 238391, 237433, 236214, 35191, 238898, 237766, 238071, 239457, 237392, 239151, 235269, 114490, 236669, 236645, 237399, 237495, 236417, 237807, 135132, 56787, 238272, 35467, 236669, 237199, 236137, 174375, 236669, 236864, 235269, 235248, 240855, 237045, 236183, 235269, 35467, 236669, 236183, 235269, 50548, 236669, 236183, 73143, 36203, 236669, 236840, 27941, 238551, 236392, 235248, 241615, 240115, 131901, 239740, 48060, 69581, 236464, 235248, 235284, 235284, 236666, 235248, 242991, 245849, 236039, 235265, 23745, 239254, 237822, 35467, 236669, 237199, 34459, 238608, 41896, 237233, 236183, 236137, 61169, 237533, 243577, 40712, 150762, 86126, 237045, 235248, 235318, 235276, 210450, 22803, 235248, 235304, 235318, 210450, 26291, 80289, 240130, 48060, 235269, 22618, 237935, 237889, 238256, 46355, 240722, 64301, 237199, 236392, 80404, 237138, 40284, 235248, 242376, 237433, 64301, 238304, 236137, 40712, 237707, 236392, 35467, 236669, 31087, 168788, 41388, 236864, 22803, 84608, 236817, 237138, 22618, 251627, 238256, 236137, 235248, 242457, 239758, 242376, 237433, 22618, 237924, 236791, 86126, 237045, 235248, 235276, 235265, 235308, 235436, 235276, 235265, 235321, 43649, 22803, 235248, 235274, 235436, 235274, 235265, 235284, 43649, 26291, 187800, 237386, 159838, 72159, 236375, 235248, 88513, 235265, 86622, 41388, 236864, 239793, 51806, 240722, 27941, 238551, 236392, 29283, 240206, 48060, 235269, 58272, 75259, 140824, 237433, 73143, 236137, 42916, 237924, 236840, 84608, 236817, 237138, 70231, 243093, 70685, 237045, 236511, 22618, 251627, 238256, 236392, 41388, 240115, 238080, 51806, 240855, 61742, 235265, 200944, 11464, 239250, 236864, 236669, 237199, 236392, 73523, 242391, 35467, 236669, 238602, 22618, 251627, 238256, 236648, 80289, 236669, 56341, 235832, 235248, 240115, 236669, 236183, 238071, 236589, 43761, 238526, 244038, 235269, 60057, 244904, 237722, 235269, 124559, 236417, 237722, 235269, 41645, 237199, 237722, 235269, 162337, 237045, 237358, 235269, 55526, 236464, 237358, 73143, 236179, 41388, 240115, 238070, 236464, 69581, 235265, 27941, 236214, 83133, 238179, 237138, 40284, 40712, 238754, 134660, 93806, 22618, 236645, 237399, 237495, 236417, 237807, 50316, 238151, 34805, 236645, 238308, 236375, 124431, 192986, 237707, 236669, 235278, 240204, 236179, 235248, 239227, 22618, 251627, 238256, 235275, 236791, 224790, 239824, 236655, 41388, 240115, 72159, 236375, 235248, 88513, 235265, 11464, 239250, 236569, 36203, 236345, 236669, 236840, 236214, 161409, 237392, 237092, 237807, 22618, 236645, 237399, 237495, 236417, 235269, 187003, 31087, 237465, 236361, 94525, 46355, 240722, 46355, 237707, 68586, 236589, 236648, 61169, 237834, 237602, 236417, 48060, 69581, 236464, 235248, 242991, 239055, 238986, 84815, 238304, 238264, 41645, 236569, 236214, 108321, 236375, 61943, 236648, 34103, 236939, 48060, 130886, 236669, 236375, 61943, 238080, 95917, 235248, 247879, 237386, 236554, 222449, 153145, 56787, 239522, 112778, 84815, 237092, 88513, 235265, 35191, 239813, 235269, 235248, 245083, 240109, 237302, 236214, 34459, 236386, 237807, 51732, 245547, 101969, 50390, 241615, 235248, 243206, 240722, 236137, 32929, 238777, 61742, 235265, 64301, 240722, 236648, 74209, 235832, 56341, 236770, 64691, 236392, 108321, 236183, 48682, 236464, 99091, 242376, 240204, 236840, 235248, 245773, 236386, 236183, 186830, 236039, 235265, 32048, 237598, 83133, 245301, 239199, 237233, 235248, 246907, 237410, 239199, 236392, 32929, 237214, 238705, 236386, 147801, 126160, 238002, 180860, 3031, 239310, 245301, 237138, 240722, 235349, 26291, 70754, 239758, 78949, 235265, 80289, 235269, 235248, 245083, 240109, 237302, 236137, 46355, 240722, 236648, 44245, 242376, 238602, 108321, 236179, 72941, 46355, 236386, 238256, 236392, 222449, 236464, 34103, 236950, 236386, 147801, 46355, 240722, 236137, 55154, 238186, 41896, 237092, 236361, 22618, 239574, 236392, 135101, 238335, 40284, 28693, 239558, 235832, 116508, 222278, 153422, 235265, 83160, 237047, 235248, 245083, 240109, 237302, 46355, 240722, 236648, 235248, 235284, 235436, 235310, 240115, 236669, 22803, 34103, 240136, 236039, 235265, 93241, 236915, 236950, 96564, 151245, 235248, 235284, 235276, 235276, 237386, 238777, 236137, 235248, 245083, 240109, 237302, 236361, 55154, 238186, 40284, 238266, 235248, 235274, 240115, 236669, 236179, 17309, 236214, 86126, 236840, 69581, 235265, 22618, 251627, 238256, 22803, 38585, 239956, 235248, 245083, 240109, 237302, 46355, 240722, 236392, 222449, 238220, 238589, 236950, 236840, 94177, 237458, 235248, 245935, 236864, 238080, 126942, 236214, 56341, 236039, 235265, 143636, 240449, 90621, 30743, 238308, 236179, 99742, 237138, 236791, 235248, 241892, 237924, 237589, 48682, 236386, 119518, 61742, 235265, 28693, 237889, 240722, 235832, 123184, 236386, 147801, 235248, 244064, 240826, 238267, 238589, 236950, 236840, 41423, 22803, 32048, 44997, 236817, 238070, 212026, 103293, 236375, 49061, 240722, 236939, 236791, 122447, 237545, 238080, 126942, 236214, 56341, 236039, 235265, 32048, 237598, 235248, 243206, 240722, 78183, 237990, 238500, 236386, 236361, 72941, 64691, 236648, 160284, 237047, 236392, 235248, 246393, 236392, 22618, 236840, 69581, 235265, 86622, 99742, 237092, 236361, 71277, 238754, 236511, 64691, 235832, 235248, 245083, 240109, 237302, 46355, 240722, 237233, 165866, 244316, 238267, 236392, 54715, 165866, 244316, 237154, 99742, 237092, 242376, 236179, 180850, 241949, 22618, 69581, 236214, 56787, 238643, 195363, 238665, 237233, 236840, 69581, 1464]\n",
      "Number of tokens: 838\n"
     ]
    }
   ],
   "source": [
    "#토큰 측정\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"google/gemma-1.1-2b-it\")\n",
    "\n",
    "# 데이터셋의 첫 번째 훈련 예시의 텍스트 가져오기\n",
    "text = dataset['train'][8]['document']\n",
    "\n",
    "# 토큰화\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Original Text: {text}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745507f8-dda1-4f98-8814-0543af75401c",
   "metadata": {},
   "source": [
    "# 3. Gemma 모델의 한국어 요약 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1be307-f676-4f54-8c7a-894abadfe3be",
   "metadata": {},
   "source": [
    "### 3.1 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249d5ac1-78ed-48b3-a67a-402a45bc962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036d6476392d416b9ab163504bd543fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BASE_MODEL = \"sh2orc/gemma-1.1-2b-ko-summarize\"\n",
    "BASE_MODEL = \"google/gemma-2-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ddcf5b-eaef-4852-9b9c-83799a08cc3e",
   "metadata": {},
   "source": [
    "### 3.2 Gemma-it의 프롬프트 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42076cb8-3f57-476f-8fe9-2e454bbe4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset['train']['document'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f19d96-8aad-425c-9c4c-7f6420bd7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc8d3da-6060-4203-9346-953d8adfb680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\n다음 글을 이해하기 쉽게 단순화해서 새로운 글로 만들어주세요:\\n\\n\"“2004년 4월 발효된 한·칠레 FTA를 시작으로 현재 한국은 총 59개국과 21건의 FTA 네트워크를 구축했다. 전 세계 국내총생산(GDP) 85%에 이른다. 주요 교역국 가운데 이 정도 FTA 네트워크를 갖춘 나라는 한국이 유일하다.”정인교 산업통상자원부(산업부) 통상교섭본부 본부장은 한국의 첫 FTA 발효 20주년을 맞아 최근 이뤄진 인터뷰에서 “미·중 패권 경쟁 심화, 자유무역 퇴조 등 국제 통상 환경이 급변하고 있지만 탄탄한 FTA 네트워크가보호막 역할을 한다”고 평가했다. 미시간주립대에서 ‘아·태 무역 자유화 효과’ 논문으로 경제학 박사 학위를 받은 정 본부장은 1995년 대외경제정책연구원(KIEP)에서 FTA 연구자로 발탁된 데 이어 인하대에서 교편을 잡으며 한국 통상 정책의 브레인 역할을 해온 국제 통상, FTA, 경제 안보 분야 전문가다. 30여 년간 통상 정책을 연구하고 설계해 온 전문가가 올 1월 통상 현장 사령관으로 뛰기 시작했다. 그는 당시 취임 일성으로 ‘통상 정책과 경제 안보의 조화, 공급망 안정, 새로운 시장 창출’을 강조했다. 2024년 한국의 첫 FTA인 칠레와 FTA를 발효한 지 20년이 지났다.“한·칠레 FTA는 연구부터 협상, 국회 비준까지 전 프로세스에 관여했다. 당시 FTA에 농업계 반대가 있어 국회를 오가며 대책 수립에도 참여해, 애착이 큰 협정이다. 한국의 첫 FTA로 FTA 정책이 자리 잡는 계기를 마련했다. 정부가 FTA를 논의한다는 말만 나와도 기업이 해당국에서 할 비즈니스를 찾는 동기를 부여했다. 한·칠레 FTA 이후 나타난 새로운 현상이었다.”FTA 20년의 성과를 평가한다면. “2003년 한국 FTA 정책 로드맵을 연구해 발표했는데, 정부가 채택했다. 그렇게 수립된 로드맵의 FTA 목표(체결 국가 수)를 초과 달성했다. 국내외적으로 한국의 FTA 정책이 가장 우수하다는 평가를 받았다. 실제 미국· 유럽연합(EU)·중국 등 거대 경제권을 포함해 총 59개국과 21건의 FTA 네트워크를 구축해 전 세계 GDP 85%에 이르는 경제 영토를 확보했다. 주요 교역국 가운데 이 정도 FTA 네트워크를 갖춘 나라는 한국이 유일하다.”한·칠레 FTA 체결 전 한국의 전 세계 대상 수출액은 약 1940억달러(약 266조원)였는데, 2023년 수출액은 6320억달러(약 869조원)로 증가했다. 걸프협력이사회(GCC)를 비롯해 중동, 남미 지역과 FTA를 타결했는데, 의미와 성과는.“지난 20년 동안 FTA 정책을 펼치면서 한국과 FTA 체결에 관심 있는 국가와는 사실상 거의 마무리했다. 그중 FTA 협상이 잘 진전되지 않았던 곳이 중동 지역이다. 지난해 한국은 사우디아라비아·아랍에미리트(UAE)·쿠웨이트·카타르·바레인·오만 등 중동 6국 경제협력체인 걸프협력이사회(GCC)와 FTA를 타결했다. UAE와는 별도로 포괄적경제동반자협정(CEPA)을 체결했다. 중동 지역은 우리 산업의 필수 원자재인 원유의 안정적인 공급원으로 그리고 자동차·가전 등 공산품의 소비처로서 우리와 오랜 협력 관계를 이어왔다. 남미도 그동안 협상이 어려웠는데, 지난해 한·에콰도르 전략적경제협력협정(SECA), 과테말라의 한·중미 FTA 가입 협상까지 이뤄냈다. 특히 GCC와 FTA 타결은 윤석열 정부 들어 대중동 정책을 강화한 게 효과를 냈다. 이른바 신(新)중동 정책으로, 윤석열 대통령은 지난해 사우디아라비아·카타르 등 중동 순방에 나섰고 FTA 협상 논의의 물꼬를 텄다.” 최근 전 세계에서 자유무역을 막는 보호주의가 강화됨에 따라 FTA 효과가 떨어질 것이라는 우려가 나온다. “자유무역 퇴조, 자국 이기주의 강화 등이 세계적인 추세가 됐고, 세계무역기구(WTO)의 규범을 지켜야 한다는 인식도 국제적으로 약화하고 있는 게 사실이다. WTO로 대변되는 자유무역 질서가 더욱 흔들린다면 그에 따른 시장 개방 약속에도 문제가 생길 수 있다. 그러나 이런 우려와 문제는 WTO 체제에 대한 도전 측면으로 볼 수 있고, FTA는 양자 간 협정이다. 때문에 서로 피해가 뻔히 보이는 상황에서 FTA를 철폐하려는 나라는 없을 것이다. WTO 체제가 굳건히 자리를 지키는 게 가장 좋지만, 그렇지 못한 상황이 발생하더라도 우리는 세계경제의 85%를 커버하는 FTA 네트워크를 구축했기 때문에 그로 인한 부정적인 영향을 최소화할 수 있다. WTO 체제가 흔들려도 일종의 보호막이 되는 것이다. 그동안 미국이 취한 조치(인플레이션 감축법 등)를 보면 FTA 대상국을 예외로 하는 경우가 꽤 있다.” “최근 몇 년 사이에 한국의 대중국 수출이 부진한 배경에는 자국 내수를 바탕으로 독자 공급망을 구축하는, 이른바 중국의 ‘쌍순환 정책’이라든가 중국 기업의 성장도 있겠지만, 미·중 갈등의 후폭풍도 분명히 작용했다고 볼 수 있다. 이제 미·중 갈등의 핵심이 첨단 산업으로 가고 있고, 이를 우리가 주의해야겠지만 동시에 중국과 거래, 전반적인 경제협력과 투자는 지속해야 한다. 미·중 갈등 과정에서 주요 7개국(G7)이 중국에 대한 정책으로 (적대적인) 디커플링(decoupling· 탈동조화)이 아닌 디리스킹(de-risking·위험 제거)을 채택한 것도 중국 시장의 중요성을 인정할 수밖에 없다는 것을 의미한다. 어쨌든 우리나라는 중국과 무역 비중이 높아 대중 관계를 원만하게 끌고 갈 수 있는 외교· 통상적 노력이 필요하다.”“우선 경제 안보와 공급망 안정이다. 과거에는 경제 문제만 생각하면 됐는데, 지금은 경제와 안보를 동일한 관점에서 바라봐야 한다. 두 번째는 글로벌 사우스(Global South· 남반구나 북반구 저위도에 위치한 개발도상국)에 대한 국제 인식이 개선되고, 이들 국가의 산업화와 수출 시장으로서 잠재력이 빠르게 커지고 있어 이들 국가와 통상 협력을 빨리 갖춰야 한다. 셋째는 전 세계에서 아직 우리와 FTA를 체결하지 않은 15%에 해당하는 국가와 통상협정을 체결해야 한다. 이들 국가는 일반적인 FTA를 하기에는 여건이 안 좋은 경우가 많아 EPA(경제동반자협정), TIPF(무역투자촉진프레임워크) 등으로 다양화할 필요가 있다. 상대국에 따라 맞춤형 FTA를 추진하는 것이라고 보면 된다. 마지막으로 국내 산업을 위해 규제할 때 통상 이슈로 제기되지 않도록 관리해야 한다. 각 부처에서 새로운 정책을 기안할 때 국제 통상 관점에서 평가하고, 통상 마찰이 생기지 않도록 사전 조처를 하는 노력을 해야 한다.”<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"다음 글을 이해하기 쉽게 단순화해서 새로운 글로 만들어주세요:\\n\\n{}\".format(doc)\n",
    "    }\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666223ea-2308-4126-a56c-a57fcec65390",
   "metadata": {},
   "source": [
    "### 3.3 Gemma-it 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61247af-ce20-47cb-ae80-5a3e40d299f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 한국, 20년의 FTA 혁신: 세계 경제의 보호막 역할\n",
      "\n",
      "**20년 동안 한국은 59개국과 21건의 FTA를 구축하며 세계 경제의 85%를 커버하는 혁신적인 통상 네트워크를 구축했습니다.** 이는 국제 통상 환경이 변화하는 현실 속에서 한국의 FTA 정책이 탄탄한 보호막 역할을 하고 있다는 것을 보여줍니다.\n",
      "\n",
      "**FTA 혁신의 핵심은 2가지입니다.**\n",
      "\n",
      "1. **경제 안보와 공급망 안정**: FTA는 단순한 무역을 넘어 경제 안보와 공급망 안정을 위한 필수적인 요소입니다. 한국은 이러한 요소를 중시하여 국내 산업의 안정성을 보장하고, 세계 경제에 대한 안정성을 확보했습니다.\n",
      "2. **글로벌 남반구와의 협력**: FTA는 단순한 무역을 넘어 글로벌 남반구의 산업화와 수출 시장 잠재력을 발휘하는 데 기여합니다. 한국은 이러한 협력을 통해 글로벌 경제의 균형을 이루고, 세계 경제의 움직임에 적극적으로 참여할 수 있도록 노력하고 있습니다.\n",
      "\n",
      "**특히, 한국은 중동과 남미 지역의 FTA 체결을 통해 경제적 협력을 강화하고 있습니다.** 이는 한국의 '신(新)중동 정책'을 통해 중동 지역의 경제 발전을 촉진하고, 세계 경제의 균형을 이루는 데 기여하는 중요한 역할을 합니다.\n",
      "\n",
      "**하지만, FTA는 단순한 무역 협상이 아닙니다.** \n",
      "\n",
      "* **WTO 체제의 변화에 대한 대응**: 세계 무역의 규범이 변화하는 현실 속에서 FTA는 WTO 체제에 대한 도전적인 역할을 수행합니다. 한국은 WTO 체제의 흔들림에 대비하여, FTA를 통해 세계 경제에 대한 안정성을 확보하고, 자국 경제의 안정을 보장하는 데 집중합니다.\n",
      "* **미·중 갈등과의 대응**: 미·중 갈등은 FTA 체결에 영향을 미칠 수 있습니다. 한국은 이러한 상황에서도 중국과의 무역 관계를 유지하고, 협력을 통해 경제적 안정성을 확보하는 노력을 계속합니다.\n",
      "* **글로벌 남반구와의 협력**: 한국은 글로벌 남반구의 산업화와 수출 시장 잠재력을 발휘하는 데 기여하기 위해 FTA를 통해 협력을 강화하고, 세계 경제의 균형을 이루는 데 기여합니다.\n",
      "\n",
      "**결론적으로, 한국은 FTA를 통해 세계 경제의 균형을 이루고, 국내 산업의 안정성을 보장하는 데 중요한 역할을 하고 있습니다.** 앞으로도 한국은 FTA를 통해 세계 경제의 변화에 적응하고, 글로벌 경제의 균형을 이루는 데 노력할 것입니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a1bfb-b47c-448e-8957-86c00cc1df02",
   "metadata": {},
   "source": [
    "# 4. Gemma 파인튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b19a9-5a04-4d67-8004-de31fe0897a7",
   "metadata": {},
   "source": [
    "#### 주의: Colab GPU 메모리 한계로 이전장 추론에서 사용했던 메모리를 비워 줘야 파인튜닝을 진행 할 수 있습니다. <br> notebook 런타임 세션을 재시작 한 후 1번과 2번의 2.1 항목까지 다시 실행하여 로드 한 후 아래 과정을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bfe441-991f-4bb8-b9a3-a1d2e9fc509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct  7 00:43:08 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.90                 Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:07:00.0  On |                  N/A |\n",
      "|  0%   40C    P8              9W /  285W |    1253MiB /  16376MiB |     15%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6368    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      7996    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A      8096    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9532    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     12688    C+G   ...y\\WindowsMCFCore\\WindowsMCFCore.exe      N/A      |\n",
      "|    0   N/A  N/A     14164    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     15692    C+G   ...tionsPlus\\logioptionsplus_agent.exe      N/A      |\n",
      "|    0   N/A  N/A     18988    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     23252    C+G   ...mpt_builder\\LogiAiPromptBuilder.exe      N/A      |\n",
      "|    0   N/A  N/A     24860    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     25512    C+G   ...ative\\Creative App\\Creative.App.exe      N/A      |\n",
      "|    0   N/A  N/A     25760    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     26772    C+G   ...on\\129.0.2792.65\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     28844    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     36644    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     37832    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     37948    C+G   ...82\\Discord\\app-1.0.9166\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     38288    C+G   ...on\\129.0.2792.65\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     38656    C+G   ...on\\129.0.2792.79\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     39440    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     42164    C+G   ...Google\\NearbyShare\\nearby_share.exe      N/A      |\n",
      "|    0   N/A  N/A     44508    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a886413-a19c-4966-9e07-ca8cdb23aa16",
   "metadata": {},
   "source": [
    "### 4.1 학습용 프롬프트 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d02140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['text'])):\n",
    "        prompt = f\"{example['text'][i]}<eos>\"\n",
    "        output_texts.append(prompt)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e4cc4b-a094-4035-906e-3edface3a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    prompt_list = []\n",
    "    for i in range(len(example['document'])):\n",
    "        prompt_list.append(r\"\"\"<bos><start_of_turn>user\n",
    "다음 글을 이해하기 쉽게 단순화해서 새로운 글로 만들어주세요:\n",
    "\n",
    "{}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "{}<end_of_turn><eos>\"\"\".format(example['document'][i], example['simplification'][i]))\n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45ab1ee-8146-4731-86ec-d673e9a67557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "다음 글을 이해하기 쉽게 단순화해서 새로운 글로 만들어주세요:\n",
      "\n",
      "\"사람은 하루 평균 15~20회 방귀를 뀐다. 방귀는 장 속에 있는 공기가 빠져나가는 정상적인 과정이지만, 속이 과도하게 부글거리거나 복부가 부어오르고 방귀 냄새가 심하게 난다면 생활습관을 점검해 볼 필요가 있다. 속 부글거림과 지독한 방귀 냄새의 원인은 장내 미생물 구성 때문인 경우가 많다. 장내 미생물이 섬유질 등 위에서 분해되지 않은 음식물을 분해하는 과정에서 이산화탄소와 수소 및 메탄이 형성되기 때문이다. 장내 미생물 구성에 따라 더 냄새나는 가스가 많이 생성될 수 있으며 일부 사람들은 냄새나는 가스를 생성하는 장내 미생물 유형이 많을 수 있다. 고기를 많이 섭취하면 방귀 냄새가 심해진다. 육류에 많이 함유된 유황이라는 화합물이 장내 미생물에 의해 썩은 달걀 냄새가 나는 황화수소 가스로 분해되기 때문이다. 만약 유제품을 섭취한 뒤 속이 부글거리거나 방귀 횟수가 잦다면 유당불내증 신호일 수 있다. 유당불내증은 체내에 유당을 분해하는 데 필요한 효소인 락타아제가 충분하지 않은 질환으로 소화되지 못한 유당이 대장의 산과 가스에 의해 복부 팽창이나 설사 등을 일으킨다. 유당불내증이 의심된다면 증상이 호전되는지 확인하기 위해 한동안 유제품 섭취를 줄이는 게 도움이 된다. 섭취를 줄인 뒤 장 증상이 나아진다면 유당 함량이 낮거나 없는 제품을 대신 섭취하는 게 좋다. 어떤 종류의 콩이든 섭취량을 늘리면 장기적인 장 건강에 유익하다. 콩은 과일이나 채소보다 더 많은 양의 섬유질이 포함돼 있다. 따라서 콩을 섭취하면 장내 미생물 구성이 다양해지고 복부 팽만을 방지하는 등의 효과가 있다. 단, 콩 섭취량을 늘리면 처음에는 방귀 횟수가 늘어날 수 있다. 따라서 콩 섭취량을 늘릴 때는 식단에 콩 한 스푼을 추가하는 것으로 시작해 몇 주에 걸쳐 반 컵으로 늘리는 것이 좋다. 이후 콩 섭취량을 유지하면 장내 미생물이 섬유질 양에 적응해 가스를 덜 방출하게 된다. 이외에 속 부글거림이나 복부 팽만을 유발하는 생활습관을 고치는 것도 한 가지 방법이다. 식사 속도가 빠르면 음식과 함께 많은 양의 공기가 유입돼 가스가 더 많이 생긴다. 껌을 씹는 습관도 마찬가지로 체내 공기 유입량을 늘린다. 맥주나 탄산음료 섭취도 자제하는 게 좋다. 탄산 속 이산화탄소가 장에 서서히 쌓이면서 가스 생성량이 늘어나기 때문이다.\"<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\"사람은 하루 평균 15~20번 정도 방귀를 뀝니다. 배출량으로 치면, 최대 1500㎖ 정도의 양이 몸 밖으로 나오는 셈인데요. 소리가 크거나 냄새가 고약해 습관적으로 방귀를 참아 본 적이 있을 거예요. 그런데 방귀를 오래 참으면 배가 아프거나 대변을 잘 보지 못하는 변비에 걸릴 수 있답니다. 평소 음식을 먹고 나면 음식물과 함께 다량의 공기가 몸속으로 들어오는데요. 몸 안에서는 방귀를 통해 체내에 축적된 가스를 내보내게 됩니다. 일부 가스는 혈액에 흡수되고, 숨을 내쉴 때 밖으로 배출되죠. 하지만 제때 방귀를 내보내지 않으면 장내에 가스가 계속 쌓이게 됩니다. 장 속에 가스를 배출시키지 못한채 가스가 계속 쌓이면 복부 팽만을 유발하고요. 복부 팽만은 장에 질소 가스가 쌓이면서, 대장이 부풀어 마치 배에 풍선이 들어있는 것처럼 배가 팽창되는 증상이에요. 심할 경우, 장의 운동 기능이 약해져 불규칙한 배변 습관이 생겨 변비로 이어질 수 있는 거예요. 그런데 유독 방귀를 자주 뀌거나 갑자기 방귀가 많아진 경우, 평소 식습관을 돌이켜보는 게 좋아요. 양배추, 콩, 브로콜리 등 식이섬유가 많은 채소는 장 기능에 좋다고 알려져 있지만 과하게 섭취할 경우 배에 가스가 잘 차기 때문에 평소보다 방귀가 잦아질 수 있거든요. 유제품을 소화시키는 '유당분해효소'가 적은 사람은 우유·요구르트 같은 유제품을 섭취하면 가스가 잘 찰 수 있고요. 이 외에도 평소 몸을 잘 움직이지 않으면 위장 운동이 떨어져 가스가 잘 차고, 과식 또한 음식물을 소화시키는 데 오랜 시간이 걸리고 위장에도 부담을 줘 방귀가 많아질 수 있답니다.\"<end_of_turn><eos>\n"
     ]
    }
   ],
   "source": [
    "val_data = dataset[\"validation\"]\n",
    "train_data = dataset[\"train\"]\n",
    "print(generate_prompt(train_data[:1])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849b4c0-16f3-44f3-bb67-7022f226ec05",
   "metadata": {},
   "source": [
    "### 4.2 QLoRA 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c085b4b-a471-4c5a-afe3-81e8e0c37756",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=6,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10bfd65-00f8-49b6-933c-a27ed4385373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4e05ef7a6e48ce948bce4798d21001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"google/gemma-2-2b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\", quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db62d4-05ef-41ad-ad7b-a9c734c1b67d",
   "metadata": {},
   "source": [
    "### 4.3 Trainer 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335301f3-c127-44e8-af43-1999e1844681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kim82\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\kim82\\anaconda3\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ba5af349e94787bbdd972cb8c1b56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1230241a342446e4a1d448e0b268b2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kim82\\anaconda3\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "   eval_dataset=val_data,\n",
    "    max_seq_length=2666,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"outputs\",\n",
    "        num_train_epochs = 4,\n",
    "        #max_steps=7000,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        warmup_ratio=0.03,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        push_to_hub=False,\n",
    "        report_to='none',\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=generate_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fd7e65-334d-4052-9ab5-3c8e71bf09a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb3b28c05644ba3a059fab37ba393a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6151, 'grad_norm': 0.7239575386047363, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1935, 'grad_norm': 0.05405891686677933, 'learning_rate': 0.00013333333333333334, 'epoch': 0.08}\n",
      "{'loss': 0.0857, 'grad_norm': 0.07947338372468948, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
      "{'loss': 0.1274, 'grad_norm': 0.05788027122616768, 'learning_rate': 0.00019793814432989693, 'epoch': 0.16}\n",
      "{'loss': 0.0931, 'grad_norm': 0.11246047168970108, 'learning_rate': 0.00019587628865979381, 'epoch': 0.2}\n",
      "{'loss': 0.131, 'grad_norm': 0.19233796000480652, 'learning_rate': 0.00019381443298969073, 'epoch': 0.24}\n",
      "{'loss': 0.1509, 'grad_norm': 0.16804923117160797, 'learning_rate': 0.00019175257731958765, 'epoch': 0.28}\n",
      "{'loss': 0.1255, 'grad_norm': 0.105956070125103, 'learning_rate': 0.00018969072164948454, 'epoch': 0.32}\n",
      "{'loss': 0.0885, 'grad_norm': 0.052614808082580566, 'learning_rate': 0.00018762886597938145, 'epoch': 0.36}\n",
      "{'loss': 0.1401, 'grad_norm': 0.08644776046276093, 'learning_rate': 0.00018556701030927837, 'epoch': 0.4}\n",
      "{'loss': 0.1161, 'grad_norm': 0.09890288859605789, 'learning_rate': 0.00018350515463917526, 'epoch': 0.44}\n",
      "{'loss': 0.137, 'grad_norm': 0.015102958306670189, 'learning_rate': 0.00018144329896907217, 'epoch': 0.48}\n",
      "{'loss': 0.1216, 'grad_norm': 0.031376685947179794, 'learning_rate': 0.0001793814432989691, 'epoch': 0.52}\n",
      "{'loss': 0.1434, 'grad_norm': 0.08553122729063034, 'learning_rate': 0.00017731958762886598, 'epoch': 0.56}\n",
      "{'loss': 0.1331, 'grad_norm': 0.04799063131213188, 'learning_rate': 0.0001752577319587629, 'epoch': 0.6}\n",
      "{'loss': 0.1296, 'grad_norm': 0.002318652579560876, 'learning_rate': 0.0001731958762886598, 'epoch': 0.64}\n",
      "{'loss': 0.1427, 'grad_norm': 0.229071244597435, 'learning_rate': 0.0001711340206185567, 'epoch': 0.68}\n",
      "{'loss': 0.1156, 'grad_norm': 0.1605565994977951, 'learning_rate': 0.00016907216494845361, 'epoch': 0.72}\n",
      "{'loss': 0.1142, 'grad_norm': 0.11827825009822845, 'learning_rate': 0.00016701030927835053, 'epoch': 0.76}\n",
      "{'loss': 0.0913, 'grad_norm': 0.1174454391002655, 'learning_rate': 0.00016494845360824742, 'epoch': 0.8}\n",
      "{'loss': 0.0835, 'grad_norm': 0.12775911390781403, 'learning_rate': 0.00016288659793814434, 'epoch': 0.84}\n",
      "{'loss': 0.1108, 'grad_norm': 0.14024488627910614, 'learning_rate': 0.00016082474226804125, 'epoch': 0.88}\n",
      "{'loss': 0.1327, 'grad_norm': 0.014394015073776245, 'learning_rate': 0.00015876288659793814, 'epoch': 0.92}\n",
      "{'loss': 0.1006, 'grad_norm': 0.0316675528883934, 'learning_rate': 0.00015670103092783506, 'epoch': 0.96}\n",
      "{'loss': 0.0859, 'grad_norm': 0.06369385123252869, 'learning_rate': 0.00015463917525773197, 'epoch': 1.0}\n",
      "{'loss': 0.1127, 'grad_norm': 0.14296160638332367, 'learning_rate': 0.00015257731958762886, 'epoch': 1.04}\n",
      "{'loss': 0.0859, 'grad_norm': 0.15372610092163086, 'learning_rate': 0.00015051546391752578, 'epoch': 1.08}\n",
      "{'loss': 0.1002, 'grad_norm': 0.11883218586444855, 'learning_rate': 0.0001484536082474227, 'epoch': 1.12}\n",
      "{'loss': 0.1076, 'grad_norm': 0.07521100342273712, 'learning_rate': 0.00014639175257731958, 'epoch': 1.16}\n",
      "{'loss': 0.1052, 'grad_norm': 0.06028321012854576, 'learning_rate': 0.0001443298969072165, 'epoch': 1.2}\n",
      "{'loss': 0.1202, 'grad_norm': 0.04516671597957611, 'learning_rate': 0.00014226804123711342, 'epoch': 1.24}\n",
      "{'loss': 0.1355, 'grad_norm': 0.2275688797235489, 'learning_rate': 0.0001402061855670103, 'epoch': 1.28}\n",
      "{'loss': 0.1132, 'grad_norm': 0.13473697006702423, 'learning_rate': 0.00013814432989690722, 'epoch': 1.32}\n",
      "{'loss': 0.1164, 'grad_norm': 0.04628504440188408, 'learning_rate': 0.00013608247422680414, 'epoch': 1.36}\n",
      "{'loss': 0.1099, 'grad_norm': 0.24087558686733246, 'learning_rate': 0.00013402061855670103, 'epoch': 1.4}\n",
      "{'loss': 0.1141, 'grad_norm': 0.059054162353277206, 'learning_rate': 0.00013195876288659794, 'epoch': 1.44}\n",
      "{'loss': 0.1205, 'grad_norm': 0.015882791951298714, 'learning_rate': 0.00012989690721649486, 'epoch': 1.48}\n",
      "{'loss': 0.1279, 'grad_norm': 0.20531423389911652, 'learning_rate': 0.00012783505154639175, 'epoch': 1.52}\n",
      "{'loss': 0.0995, 'grad_norm': 0.1241752952337265, 'learning_rate': 0.00012577319587628866, 'epoch': 1.56}\n",
      "{'loss': 0.1295, 'grad_norm': 0.016033275052905083, 'learning_rate': 0.00012371134020618558, 'epoch': 1.6}\n",
      "{'loss': 0.108, 'grad_norm': 0.0609520822763443, 'learning_rate': 0.00012164948453608247, 'epoch': 1.64}\n",
      "{'loss': 0.1167, 'grad_norm': 0.23607632517814636, 'learning_rate': 0.00011958762886597938, 'epoch': 1.68}\n",
      "{'loss': 0.0852, 'grad_norm': 0.028160851448774338, 'learning_rate': 0.0001175257731958763, 'epoch': 1.72}\n",
      "{'loss': 0.0986, 'grad_norm': 0.07356772571802139, 'learning_rate': 0.00011546391752577319, 'epoch': 1.76}\n",
      "{'loss': 0.0943, 'grad_norm': 0.044411998242139816, 'learning_rate': 0.0001134020618556701, 'epoch': 1.8}\n",
      "{'loss': 0.125, 'grad_norm': 0.014246882870793343, 'learning_rate': 0.00011134020618556702, 'epoch': 1.84}\n",
      "{'loss': 0.0935, 'grad_norm': 0.015488376840949059, 'learning_rate': 0.00010927835051546391, 'epoch': 1.88}\n",
      "{'loss': 0.1075, 'grad_norm': 0.016083715483546257, 'learning_rate': 0.00010721649484536083, 'epoch': 1.92}\n",
      "{'loss': 0.0936, 'grad_norm': 0.029397526755928993, 'learning_rate': 0.00010515463917525774, 'epoch': 1.96}\n",
      "{'loss': 0.1001, 'grad_norm': 0.029871344566345215, 'learning_rate': 0.00010309278350515463, 'epoch': 2.0}\n",
      "{'loss': 0.0751, 'grad_norm': 0.0013985905097797513, 'learning_rate': 0.00010103092783505155, 'epoch': 2.04}\n",
      "{'loss': 0.0891, 'grad_norm': 0.029036326333880424, 'learning_rate': 9.896907216494846e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0707, 'grad_norm': 0.04370567575097084, 'learning_rate': 9.690721649484537e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0756, 'grad_norm': 0.029136721044778824, 'learning_rate': 9.484536082474227e-05, 'epoch': 2.16}\n",
      "{'loss': 0.1086, 'grad_norm': 0.04096101596951485, 'learning_rate': 9.278350515463918e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0968, 'grad_norm': 0.04139316454529762, 'learning_rate': 9.072164948453609e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0799, 'grad_norm': 0.01376919075846672, 'learning_rate': 8.865979381443299e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0908, 'grad_norm': 0.012918954715132713, 'learning_rate': 8.65979381443299e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0932, 'grad_norm': 0.3430786430835724, 'learning_rate': 8.453608247422681e-05, 'epoch': 2.36}\n",
      "{'loss': 0.095, 'grad_norm': 0.001019151764921844, 'learning_rate': 8.247422680412371e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0817, 'grad_norm': 0.015033653937280178, 'learning_rate': 8.043298969072165e-05, 'epoch': 2.44}\n",
      "{'loss': 0.1183, 'grad_norm': 0.0026049036532640457, 'learning_rate': 7.837113402061856e-05, 'epoch': 2.48}\n",
      "{'loss': 0.1069, 'grad_norm': 0.028434382751584053, 'learning_rate': 7.630927835051547e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1026, 'grad_norm': 0.0021856650710105896, 'learning_rate': 7.424742268041237e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0839, 'grad_norm': 0.014753506518900394, 'learning_rate': 7.218556701030928e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1322, 'grad_norm': 0.0031164996325969696, 'learning_rate': 7.012371134020619e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0905, 'grad_norm': 0.05375770851969719, 'learning_rate': 6.806185567010309e-05, 'epoch': 2.68}\n",
      "{'loss': 0.104, 'grad_norm': 0.0014343232614919543, 'learning_rate': 6.6e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1074, 'grad_norm': 0.02784525416791439, 'learning_rate': 6.393814432989691e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0732, 'grad_norm': 0.0008263206109404564, 'learning_rate': 6.187628865979381e-05, 'epoch': 2.8}\n",
      "{'loss': 0.1104, 'grad_norm': 0.014572372660040855, 'learning_rate': 5.9814432989690726e-05, 'epoch': 2.84}\n",
      "{'loss': 0.1052, 'grad_norm': 0.0403384305536747, 'learning_rate': 5.775257731958763e-05, 'epoch': 2.88}\n",
      "{'loss': 0.111, 'grad_norm': 0.32646477222442627, 'learning_rate': 5.569072164948453e-05, 'epoch': 2.92}\n",
      "{'loss': 0.1005, 'grad_norm': 0.028427598997950554, 'learning_rate': 5.362886597938145e-05, 'epoch': 2.96}\n",
      "{'loss': 0.0843, 'grad_norm': 0.3099822998046875, 'learning_rate': 5.156701030927835e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0963, 'grad_norm': 0.00197863788343966, 'learning_rate': 4.950515463917526e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0713, 'grad_norm': 0.013681040145456791, 'learning_rate': 4.744329896907217e-05, 'epoch': 3.08}\n",
      "{'loss': 0.0766, 'grad_norm': 0.0025068558752536774, 'learning_rate': 4.538144329896907e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0682, 'grad_norm': 0.027088232338428497, 'learning_rate': 4.331958762886598e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0594, 'grad_norm': 0.027293575927615166, 'learning_rate': 4.125773195876289e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0679, 'grad_norm': 0.01372383814305067, 'learning_rate': 3.9216494845360826e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0727, 'grad_norm': 0.013710285536944866, 'learning_rate': 3.7154639175257736e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0797, 'grad_norm': 0.026267968118190765, 'learning_rate': 3.5092783505154645e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0912, 'grad_norm': 0.0025191917084157467, 'learning_rate': 3.303092783505155e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0905, 'grad_norm': 0.014345616102218628, 'learning_rate': 3.0969072164948457e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0772, 'grad_norm': 0.014541949145495892, 'learning_rate': 2.8907216494845362e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0879, 'grad_norm': 0.0022753840312361717, 'learning_rate': 2.6845360824742272e-05, 'epoch': 3.48}\n",
      "{'loss': 0.1024, 'grad_norm': 0.38982024788856506, 'learning_rate': 2.4783505154639178e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0819, 'grad_norm': 0.013542523607611656, 'learning_rate': 2.2721649484536084e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0989, 'grad_norm': 0.015070483088493347, 'learning_rate': 2.065979381443299e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0818, 'grad_norm': 0.026883309707045555, 'learning_rate': 1.85979381443299e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0923, 'grad_norm': 0.005390362814068794, 'learning_rate': 1.6536082474226805e-05, 'epoch': 3.68}\n",
      "{'loss': 0.1001, 'grad_norm': 0.0018345783464610577, 'learning_rate': 1.447422680412371e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0897, 'grad_norm': 0.40018564462661743, 'learning_rate': 1.2412371134020618e-05, 'epoch': 3.76}\n",
      "{'loss': 0.081, 'grad_norm': 0.3571546673774719, 'learning_rate': 1.0350515463917526e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0892, 'grad_norm': 0.00354250380769372, 'learning_rate': 8.288659793814433e-06, 'epoch': 3.84}\n",
      "{'loss': 0.0801, 'grad_norm': 0.0034803699236363173, 'learning_rate': 6.22680412371134e-06, 'epoch': 3.88}\n",
      "{'loss': 0.0616, 'grad_norm': 0.00243196333758533, 'learning_rate': 4.164948453608248e-06, 'epoch': 3.92}\n",
      "{'loss': 0.0746, 'grad_norm': 0.0025261694099754095, 'learning_rate': 2.1030927835051548e-06, 'epoch': 3.96}\n",
      "{'loss': 0.0855, 'grad_norm': 0.4444645941257477, 'learning_rate': 4.123711340206186e-08, 'epoch': 4.0}\n",
      "{'train_runtime': 140975.2069, 'train_samples_per_second': 0.284, 'train_steps_per_second': 0.071, 'train_loss': 0.12674082674980164, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10000, training_loss=0.12674082674980164, metrics={'train_runtime': 140975.2069, 'train_samples_per_second': 0.284, 'train_steps_per_second': 0.071, 'total_flos': 5.111854541053747e+16, 'train_loss': 0.12674082674980164, 'epoch': 4.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca74e51-15ec-403a-90f1-4b7eeb2c723b",
   "metadata": {},
   "source": [
    "### 4.4 Finetuned Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2bba87d-d95c-4a57-9eb1-c02d81ad7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAPTER_MODEL = \"lora_adapter\"\n",
    "\n",
    "trainer.model.save_pretrained(ADAPTER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9fcda0-1d7a-4443-9b1c-7d45490daafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!ls -alh lora_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a2a6d7-ece4-472a-981f-fb6599d1d307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kim82\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1462: UserWarning: Current model requires 6656 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23f0564112e4ff3a66526ec5f8c40c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kim82\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\modeling.py:1462: UserWarning: Current model requires 13312 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gemma-2-2b-it\\\\tokenizer_config.json',\n",
       " 'gemma-2-2b-it\\\\special_tokens_map.json',\n",
       " 'gemma-2-2b-it\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained('gemma-2-2b-it')\n",
    "# 토크나이저 저장\n",
    "tokenizer.save_pretrained('gemma-2-2b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a764bbc-069d-400c-bca4-09e799bf0fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "!ls -alh ./gemma-2-2b-it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2c237-71f4-47c2-bad4-181dadb6cc98",
   "metadata": {},
   "source": [
    "# 5. Gemma 한국어 요약 모델 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587dfc7-cf7c-4072-a8f7-6ceb1e90a532",
   "metadata": {},
   "source": [
    "#### 주의: 마찬가지로 Colab GPU 메모리 한계로 학습 시 사용했던 메모리를 비워 줘야 파인튜닝을 진행 할 수 있습니다. <br> notebook 런타임 세션을 재시작 한 후 1번과 2번의 2.1 항목까지 다시 실행하여 로드 한 후 아래 과정을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906ed4dd-270f-4000-84de-ede6885c0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 10 19:05:19 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.90                 Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:07:00.0  On |                  N/A |\n",
      "| 34%   40C    P8             12W /  285W |    1559MiB /  16376MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      7228    C+G   ...tionsPlus\\logioptionsplus_agent.exe      N/A      |\n",
      "|    0   N/A  N/A     11448    C+G   ...y\\WindowsMCFCore\\WindowsMCFCore.exe      N/A      |\n",
      "|    0   N/A  N/A     12620    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     18044    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     22316    C+G   ...mpt_builder\\LogiAiPromptBuilder.exe      N/A      |\n",
      "|    0   N/A  N/A     25364    C+G   ...on\\129.0.2792.79\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     27564    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     28676    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     28700    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     30812    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     32188    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     33000    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     33140    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     36944    C+G   ...82\\Discord\\app-1.0.9167\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     37816    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     39024    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     42328    C+G   ...Google\\NearbyShare\\nearby_share.exe      N/A      |\n",
      "|    0   N/A  N/A     43128    C+G   ...ative\\Creative App\\Creative.App.exe      N/A      |\n",
      "|    0   N/A  N/A     43388    C+G   ...on\\129.0.2792.79\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78399236-63b5-41af-9cee-a7233e23a9db",
   "metadata": {},
   "source": [
    "### 5.1 Fine-tuned 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33644d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2367fde80c2646b2af99b8e4d0babce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"google/gemma-1.1-2b-it\"\n",
    "FINETUNE_MODEL = \"./gemma-1.1-2b-it-sim-ko\"\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(\n",
    "    FINETUNE_MODEL,    \n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config, \n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d5ba97-91ca-48c3-b9a2-ba9bea6d7b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8f67a5871d4496afdb54d1562274ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BASE_MODEL = \"google/gemma-2-2b-it\"\n",
    "BASE_MODEL = \"google/gemma-1.1-2b-it\"\n",
    "FINETUNE_MODEL = \"./gemma-1.1-2b-it-sim-ko-4096\"\n",
    "\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34718c-ce52-4d68-ac8c-c18b6483b15b",
   "metadata": {},
   "source": [
    "### 5.2 Fine-tuned 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f0fc82-abaf-49df-9254-7ccee2e74d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_finetuned = pipeline(\"text-generation\", model=finetune_model, tokenizer=tokenizer, max_new_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f915638-d859-446f-bc78-070650421ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset['test']['document'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396788e7-4b80-46d7-980f-38fcb892a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\n다음 글을 이해하기 쉽게 단순화해서 새로운 글로 만들어주세요:\\n\\n\"최근 현지식당 콘셉트를 위해 외국어 간판이나 메뉴판을 내세운 가게들이 늘어나는 가운데, 대구의 한 일식당이 메뉴판 음식 가격을 엔화로만 표기한 사실이 알려져 갑론을박이 일고 있다.지난 28일 엑스(옛 트위터)에는 한 시민이 대구 동성로 한 일식당을 다녀왔다가 황당한 경험을 했다는 글이 올라왔다. 해당 시민은 “현지 기분을 느끼란 것이냐”라며 메뉴판 사진을 공개했다.공개된 메뉴판에는 ‘엔화(￥)로 표기된 가격은 ‘0′을 붙여 원화로 계산해 주세요’라는 안내 문구가 적혀 있었다. 실제 주메뉴부터 토핑, 음료까지 모두 ‘원’이 아닌 엔화로 표기돼있다. 가게에서 판매하는 오징어 먹물 리소토 몬자야키는 1580엔으로 적혀 있어 15800원을 내야 하는 셈이다.이를 접한 네티즌들은 “엔화로 표기했으면 줏대 있게 가격도 엔화 기준으로 (돈을) 받을 것이지 손해는 보기 싫다고 ‘0′ 하나 더 붙여서 저세상 환율을 적용하는 것은 대체 무엇이냐”고 지적했다.다른 네티즌들도 “메뉴 이름은 한글이고 가격 표기는 엔화인 게 웃긴 상황이다”, “엔화로 적어두고 엔화를 안 받는 건 무슨 콘셉트냐” 등 반응을 보였다.일부는 “그냥 메뉴 콘셉트이니 불편하다고 느끼지 않는다”, “일식집이라고 하는데 굳이 나쁘게 볼 것 있냐” 등의 의견을 내놓기도 했다.현행법상 식당과 카페 등 메뉴판에 한글 표기가 없어도 불법이 아니다. 옥외광고물법에 따르면 광고물의 문자는 원칙적으로 한글 맞춤법이나 국어의 로마자표기법, 외래어표기법 등에 맞춰 한글로 표시해야 하며 외국어로 기재하는 경우 한글을 병기해야 한다. 이를 위반할 시 500만원 이하 과태료가 부과될 수 있다.하지만 식당 등 내부에서 손님에게만 제공하는 메뉴판은 옥외광고물에 해당하지 않아 현재는 법적으로 규제할 방법이 없다.이에 지난해 8월 조명희 국민의힘 의원은 카페와 음식점 등 대중 이용 시설에서 한글 안내판이나 메뉴판을 제공하도록 하는 내용의 국어기본법 개정안을 발의했다. 조 의원은 일상에서의 무분별한 외국어 사용으로 국어문화 형성에 부정적 영향을 끼친다고 지적했다.\"<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"다음 글을 이해하기 쉽게 단순화해서 새로운 글로 만들어주세요:\\n\\n{}\".format(doc)\n",
    "    }\n",
    "]\n",
    "prompt = pipe_finetuned.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f1f711-0ba7-4087-8317-b0e7f4246aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"최근 현지식당에서 메뉴판에 외국어 표기가 없는 곳이 많아지고 있어요. 메뉴판에는 외국인 손님이 주문을 내는 걸 보면 외국인이 먹고 싶은 음식이 많다는 얘기죠. 외국인 손님이 먹고 싶은 음식이 많아지면 주문이 줄어들고, 먹고 싶은 음식을 먹을 사람이 줄어들어요. 먹고 싶은 음식을 먹을 사람이 줄면 음식 가격도 내야 하는 거죠. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 하는 거죠.이런 상황이 벌어지면 우리는 먹고 싶은 음식을 먹는 사람이 줄어들면 음식 가격도 내야 한다는 거예요. 우리나라는 2022년 1월 10일, 현지식당 메뉴판에 한글 표기가 없는 곳이 많다는 보고서를 발표했어요. 메뉴판에 한글 표기가 없는 곳은 주문이 줄어들고, 음식 가격도 내야 한다는 내용이었죠.현지식당 메뉴판에 한글 표기가 없는 곳은 1000여 곳 중 3000여 곳에 달하답니다. 메뉴판에 한글 표기가 없는 곳이 많아지면 외국인 손님이 먹고 싶은 음식이 많아지고, 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고 싶은 음식이 많아지면 먹고 싶은 음식을 먹는 사람도 줄어들어요. 먹고 싶은 음식을 먹는 사람이 줄면 음식 가격도 내야 한다는 건데요. 외국인 손님이 먹고\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_finetuned(\n",
    "    prompt,\n",
    "    do_sample=True, # 샘플링 기법 적용\n",
    "    temperature=0.2, #0부터 1까지. 높으면 높을 수록 모델이 더 다양한 텍스트 생성\n",
    "    top_k=50, # 텍스트를 생성할 때 상위 K개의 후보 토큰까지 사용\n",
    "    top_p=0.95 # 누적 상위 P% 확률의 후보 토큰까지 사용\n",
    "  #  no_repeat_ngram_size=10,\n",
    "  #  num_beams=10, \n",
    "  #  early_stopping=True,\n",
    "  #  num_return_sequences=5\n",
    "  #  repetition_penalty=1.2\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
